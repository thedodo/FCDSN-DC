{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DC train notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) DI Dominik Hirner BSc. \n",
    "Institute for graphics and vision (ICG)\n",
    "University of Technology Graz, Austria\n",
    "E-mail: dominik.hirner@icg.tugraz.at\n",
    "\n",
    "This notebook is the equivalent to the DC_train.py script in the root folder of this repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import re\n",
    "import time\n",
    "from torch import optim\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import random\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor = torch.cuda.FloatTensor\n",
    "LTensor = torch.cuda.LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 7\n",
    "nr_epochs = 200000000\n",
    "batch_size = 1000\n",
    "model_name = 'Incons'\n",
    "s_range = 190\n",
    "chan = 10\n",
    "dataset = 'ETH'\n",
    "n_conv = 70\n",
    "lr = 0.000006\n",
    "\n",
    "disp_list = '/media/HDD/ICPR-AblationStudies/fillOld_TrainedFill/Out/ETH/simb/*_s.pfm'\n",
    "gt_list = '/media/HDD/ICPR-AblationStudies/fillOld_TrainedFill/Out/ETH/simb/*disp0GT.pfm'\n",
    "im_left_list = '/media/HDD/ICPR-AblationStudies/fillOld_TrainedFill/Out/ETH/simb/*im0.png'\n",
    "out_folder = '/media/HDD/ICPR-AblationStudies/github_temp/save/'\n",
    "w_folder = '/media/HDD/ICPR-AblationStudies/github_temp/save/fill/'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_list_f = glob.glob(disp_list)\n",
    "disp_list_f = sorted(disp_list_f)\n",
    "\n",
    "gt_list_f = glob.glob(gt_list)\n",
    "gt_list_f = sorted(gt_list_f)\n",
    "\n",
    "im_left_list_f = glob.glob(im_left_list)\n",
    "im_left_list_f = sorted(im_left_list_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readPFM(file):\n",
    "    \n",
    "    file = open(file, 'rb')\n",
    "    color = None\n",
    "    width = None\n",
    "    height = None\n",
    "    scale = None\n",
    "    endian = None\n",
    "\n",
    "    header = file.readline().decode('utf-8').rstrip()\n",
    "    if header == 'PF':\n",
    "        color = True\n",
    "    elif header == 'Pf':\n",
    "        color = False\n",
    "    else:\n",
    "        raise Exception('Not a PFM file.')\n",
    "\n",
    "    dim_match = re.match(r'^(\\d+)\\s(\\d+)\\s$', file.readline().decode('utf-8'))\n",
    "    if dim_match:\n",
    "        width, height = map(int, dim_match.groups())\n",
    "    else:\n",
    "        raise Exception('Malformed PFM header.')\n",
    "\n",
    "    scale = float(file.readline().decode('utf-8').rstrip())\n",
    "    if scale < 0:  # little-endian\n",
    "        endian = '<'\n",
    "        scale = -scale\n",
    "    else:\n",
    "        endian = '>'  # big-endian\n",
    "\n",
    "    data = np.fromfile(file, endian + 'f')\n",
    "    shape = (height, width, 3) if color else (height, width)\n",
    "\n",
    "    data = np.reshape(data, shape)\n",
    "    data = np.flipud(data)\n",
    "    return data, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writePFM(file, image, scale=1):\n",
    "    file = open(file, 'wb')\n",
    "\n",
    "    color = None\n",
    "\n",
    "    if image.dtype.name != 'float32':\n",
    "        raise Exception('Image dtype must be float32.')\n",
    "\n",
    "    image = np.flipud(image)\n",
    "\n",
    "    if len(image.shape) == 3 and image.shape[2] == 3:  # color image\n",
    "        color = True\n",
    "    elif len(image.shape) == 2 or len(image.shape) == 3 and image.shape[2] == 1:  # greyscale\n",
    "        color = False\n",
    "    else:\n",
    "        raise Exception('Image must have H x W x 3, H x W x 1 or H x W dimensions.')\n",
    "\n",
    "    file.write('PF\\n'.encode() if color else 'Pf\\n'.encode())\n",
    "    file.write('%d %d\\n'.encode() % (image.shape[1], image.shape[0]))\n",
    "\n",
    "    endian = image.dtype.byteorder\n",
    "\n",
    "    if endian == '<' or endian == '=' and sys.byteorder == 'little':\n",
    "        scale = -scale\n",
    "\n",
    "    file.write('%f\\n'.encode() % scale)\n",
    "\n",
    "    image.tofile(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpdateInconsNW(nn.Module):\n",
    "    def __init__(self,img_ch=chan):\n",
    "        super(UpdateInconsNW,self).__init__()\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "        self.Conv1 = nn.Conv2d(img_ch, n_conv, kernel_size = 3,stride=1,padding = 1,dilation = 1, bias=True)\n",
    "        self.Conv2 = nn.Conv2d(n_conv, n_conv, kernel_size=3,stride=1,padding = 1,dilation = 1, bias=True)        \n",
    "        self.Conv3 = nn.Conv2d(n_conv + 3, img_ch, kernel_size=3,stride=1,padding = 1,dilation = 1, bias=True)\n",
    "\n",
    "\n",
    "    def forward(self,x_in, im):\n",
    "\n",
    "        x1 = self.Conv1(x_in)\n",
    "        x1 = self.act(x1)\n",
    "\n",
    "        x2 = self.Conv2(x1)\n",
    "        x2 = self.act(x2)\n",
    "\n",
    "        x3im = torch.cat((x2,im),axis = 1)\n",
    "\n",
    "        x3 = self.Conv3(x3im)\n",
    "        x3 = self.softmax(x3)\n",
    "\n",
    "        return x3\n",
    "\n",
    "updInc = UpdateInconsNW()\n",
    "updInc = updInc.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcEPE(disp, gt_fn):\n",
    "    \n",
    "    gt = gt_fn\n",
    "\n",
    "    gt[np.where(gt == np.inf)] = -100\n",
    "    \n",
    "    mask = gt > 0\n",
    "    \n",
    "    disp = np.squeeze(disp)\n",
    "    disp = disp[mask]\n",
    "    gt = gt[mask]\n",
    "\n",
    "    nr_px = len(gt)\n",
    "\n",
    "    abs_error_im = np.abs(disp - gt)\n",
    "\n",
    "    five_pe = (float(np.count_nonzero(abs_error_im >= 5.0) ) / nr_px) * 100.0  \n",
    "    four_pe = (float(np.count_nonzero(abs_error_im >= 4.0) ) / nr_px) * 100.0  \n",
    "    three_pe = (float(np.count_nonzero(abs_error_im >= 3.0) ) / nr_px) * 100.0  \n",
    "    two_pe = (float(np.count_nonzero(abs_error_im >= 2.0) ) / nr_px) * 100.0        \n",
    "    one_pe = (float(np.count_nonzero(abs_error_im >= 1.0) ) / nr_px) * 100.0        \n",
    "    pf_pe = (float(np.count_nonzero(abs_error_im >= 0.5) ) / nr_px) * 100.0  \n",
    "        \n",
    "    return five_pe, four_pe, three_pe, two_pe, one_pe, pf_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findGTInDispArr(chan, arr, gt, offset):\n",
    "    c,w,h = arr.shape\n",
    "    first_arr = np.zeros((w,h))\n",
    "    \n",
    "    #TO SEE HOW MANY ARE STILL NOT USABLE!!!\n",
    "    first_arr = first_arr * -1\n",
    "    \n",
    "    for w_ in range(0,w-1):\n",
    "      for h_ in range(0,h-1):\n",
    "        found = 0\n",
    "        for i in range(0,chan):\n",
    "            if (int(arr[i,w_,h_]) == (int(gt[w_,h_])+offset)):\n",
    "                first_arr[w_,h_] = i\n",
    "                found = 1\n",
    "                break\n",
    "        if(found == 0):\n",
    "            for i in range(0,chan):\n",
    "                if (int(arr[i,w_,h_]) == (int(gt[w_,h_])+offset+1)):\n",
    "                    first_arr[w_,h_] = i\n",
    "                    found = 1\n",
    "                    break\n",
    "        if(found == 0):\n",
    "            for i in range(0,chan):\n",
    "                if (int(arr[i,w_,h_]) == (int(gt[w_,h_])+offset-1)):\n",
    "                    first_arr[w_,h_] = i\n",
    "                    found = 1\n",
    "                    break\n",
    "        if(found == 0):\n",
    "            for i in range(0,chan):\n",
    "                if (int(arr[i,w_,h_]) == (int(gt[w_,h_])+offset+2)):\n",
    "                    first_arr[w_,h_] = i\n",
    "                    found = 1\n",
    "                    break\n",
    "        if(found == 0):\n",
    "            for i in range(0,chan):\n",
    "                if (int(arr[i,w_,h_]) == (int(gt[w_,h_])+offset-2)):\n",
    "                    first_arr[w_,h_] = i\n",
    "                    found = 1\n",
    "                    break         \n",
    "    return first_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findGTInDispArrSingle(arr, gt, offset):\n",
    "    \n",
    "    first = -1\n",
    "    #this loop could probably be sped up right?\n",
    "    for i in range(0,len(arr)):\n",
    "        if (int(arr[i]) == (int(gt)+offset)):\n",
    "            first = i\n",
    "            break\n",
    "            \n",
    "    return first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadMB(disp_list_f, gt_list_f, im_left_list_f):\n",
    "    \n",
    "    disp_list = []\n",
    "    gt_list = []\n",
    "    im_list = []\n",
    "    names = []\n",
    "          \n",
    "    for i in range(0,len(disp_list_f)):\n",
    "        \n",
    "        cur_disp, _ = readPFM(disp_list_f[i])\n",
    "        cur_gt, _ = readPFM(gt_list_f[i])\n",
    "        \n",
    "        cur_disp[np.isnan(cur_disp)] = 0\n",
    "        cur_disp[np.isinf(cur_disp)] = 0\n",
    "\n",
    "        cur_gt[np.isnan(cur_gt)] = 0\n",
    "        cur_gt[np.isinf(cur_gt)] = 0\n",
    "                    \n",
    "        cur_im = cv2.imread(im_left_list_f[i])\n",
    "        cur_im = (cur_im - np.min(cur_im)) / (np.max(cur_im) - np.min(cur_im))\n",
    "        \n",
    "        disp_list.append(cur_disp)\n",
    "        gt_list.append(cur_gt)\n",
    "        im_list.append(cur_im)\n",
    "        names.append(disp_list_f[i].split('/')[-2])\n",
    "        \n",
    "    return disp_list, gt_list,im_list,names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadKitti2012(disp_list_f, gt_list_f, im_left_list_f):\n",
    "\n",
    "    disp_list = []\n",
    "    gt_list = []\n",
    "    im_list = []\n",
    "    names = []\n",
    "    \n",
    "    for i in range(0,len(disp_list_f)):\n",
    "        \n",
    "        cur_im = cv2.imread(im_left_list_f[i])\n",
    "        #normalize\n",
    "        cur_im = (cur_im - np.min(cur_im)) / (np.max(cur_im) - np.min(cur_im))\n",
    "        cur_disp, _ = readPFM(disp_list_f[i])\n",
    "        cur_gt, _ = readPFM(gt_list_f[i])\n",
    "        \n",
    "        cur_disp[np.isnan(cur_disp)] = 0\n",
    "        cur_disp[np.isinf(cur_disp)] = 0\n",
    "\n",
    "        cur_gt[np.isnan(cur_gt)] = 0\n",
    "        cur_gt[np.isinf(cur_gt)] = 0\n",
    "        \n",
    "        im_list.append(cur_im)\n",
    "        gt_list.append(cur_gt)\n",
    "        disp_list.append(cur_disp)\n",
    "        names.append(disp_list_f[i].split('/')[-1].split('.')[0])\n",
    "        \n",
    "    return disp_list, gt_list, im_list, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadKitti2015(disp_list_f, gt_list_f, im_left_list_f):\n",
    "\n",
    "    disp_list = []\n",
    "    gt_list = []\n",
    "    im_list = []\n",
    "    names = []\n",
    "    \n",
    "    for i in range(0,len(disp_list_f)):\n",
    "        \n",
    "        cur_im = cv2.imread(im_left_list_f[i])\n",
    "        \n",
    "        #normalize\n",
    "        cur_im = (cur_im - np.min(cur_im)) / (np.max(cur_im) - np.min(cur_im))\n",
    "        \n",
    "        cur_disp, _ = readPFM(disp_list_f[i])\n",
    "        cur_gt, _ = readPFM(gt_list_f[i])\n",
    "        \n",
    "        cur_disp[np.isnan(cur_disp)] = 0\n",
    "        cur_disp[np.isinf(cur_disp)] = 0\n",
    "\n",
    "        cur_gt[np.isnan(cur_gt)] = 0\n",
    "        cur_gt[np.isinf(cur_gt)] = 0\n",
    "                \n",
    "        im_list.append(cur_im)\n",
    "        gt_list.append(cur_gt)\n",
    "        disp_list.append(cur_disp)\n",
    "        names.append(disp_list_f[i].split('/')[-1].split('.')[0])\n",
    "        \n",
    "    return disp_list, gt_list, im_list, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadETH3D(disp_list_f, gt_list_f, im_left_list_f):\n",
    "\n",
    "    im_list = []\n",
    "    gt_list = []\n",
    "    disp_list = []\n",
    "    names = []\n",
    "    \n",
    "    for i in range(0,len(disp_list_f)):\n",
    "        \n",
    "        cur_im = cv2.imread(im_left_list_f[i])\n",
    "        \n",
    "        cur_im = (cur_im - np.min(cur_im)) / (np.max(cur_im) - np.min(cur_im))\n",
    "        cur_disp, _ = readPFM(disp_list_f[i])\n",
    "        cur_gt, _ = readPFM(gt_list_f[i])\n",
    "        \n",
    "        cur_disp[np.isnan(cur_disp)] = 0\n",
    "        cur_disp[np.isinf(cur_disp)] = 0\n",
    "\n",
    "        cur_gt[np.isnan(cur_gt)] = 0\n",
    "        cur_gt[np.isinf(cur_gt)] = 0\n",
    "                \n",
    "        im_list.append(cur_im)\n",
    "        gt_list.append(cur_gt)\n",
    "        disp_list.append(cur_disp)\n",
    "        names.append(disp_list_f[i].split('/')[-1].split('.')[0])\n",
    "        \n",
    "\n",
    "    return disp_list, gt_list, im_list, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createShiftPytZero(image, chan):\n",
    "    \n",
    "    counter = np.ones((image.shape[0],image.shape[1])) * chan\n",
    "    counterT = Variable(Tensor(counter))\n",
    "    \n",
    "    shift_arr = np.zeros((chan,image.shape[0],image.shape[1]))\n",
    "    shift_arrT = Variable(Tensor(shift_arr))\n",
    "\n",
    "    i = 0\n",
    "    while(torch.sum(counterT) > 0):\n",
    "\n",
    "        if(i == image.shape[1]):\n",
    "            i = 0\n",
    "            \n",
    "        if(i % 2 == 0):                \n",
    "            ex_s = torch.roll(image,-i)\n",
    "            #ex_s = torch.roll(image,i)\n",
    "            #set left side of tensor to zero to mimick old createshift\n",
    "            ex_s[:,chan-i:chan] = 0\n",
    "            \n",
    "        if(i % 2 == 1):\n",
    "            ex_s = torch.roll(image,i)\n",
    "            #ex_s = torch.roll(image,-i)\n",
    "            #set right side of tensor to zero to mimick old createshift\n",
    "            ex_s[:,0:i] = 0\n",
    "            \n",
    "        \n",
    "        idc = torch.nonzero(ex_s, as_tuple = True)\n",
    "\n",
    "        counterT[idc[0],idc[1]] += -1\n",
    "        \n",
    "        max_loop = torch.min(counterT).cpu().data.numpy().astype(np.int)\n",
    "\n",
    "        #it overwrites lines that already have values with 0's!!!\n",
    "        for d in range(max_loop,chan):\n",
    "            \n",
    "            idx_cur = torch.where(counterT == d)\n",
    "            slice_tensor = torch.zeros(ex_s.shape[0], ex_s.shape[1]).cuda()\n",
    "            slice_tensor[idx_cur[0].long(),idx_cur[1].long()] = ex_s[idx_cur[0].long(),idx_cur[1].long()]\n",
    "            \n",
    "            idc_slice = torch.nonzero(slice_tensor, as_tuple = True)\n",
    "            shift_arrT[d, idc_slice[0].long(),idc_slice[1].long()] = ex_s[idc_slice[0].long(),idc_slice[1].long()]\n",
    "            \n",
    "        counterT[counterT < 0] = 0\n",
    "        i = i + 1\n",
    "                    \n",
    "    return shift_arrT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_image(X, dx, dy):\n",
    "    X = np.roll(X, dy, axis=0)\n",
    "    X = np.roll(X, dx, axis=1)\n",
    "    if dy>0:\n",
    "        X[:dy, :] = 0\n",
    "    elif dy<0:\n",
    "        X[dy:, :] = 0\n",
    "    if dx>0:\n",
    "        X[:, :dx] = 0\n",
    "    elif dx<0:\n",
    "        X[:, dx:] = 0\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClass(disp_list_f, gt_list_f, chan):\n",
    "    \n",
    "    keep_list = []\n",
    "    upd_list = []\n",
    "    disp_list = []\n",
    "    gt_list = []\n",
    "    nolabel_list = []\n",
    "    \n",
    "    for i in range(0,len(disp_list_f)): \n",
    "\n",
    "        \n",
    "        cur_disp, _ = readPFM(disp_list_f[i])\n",
    "        cur_gt, _ = readPFM(gt_list_f[i])\n",
    "        \n",
    "        cur_disp[np.isnan(cur_disp)] = 0\n",
    "        cur_disp[np.isinf(cur_disp)] = 0\n",
    "\n",
    "        cur_gt[np.isnan(cur_gt)] = 0\n",
    "        cur_gt[np.isinf(cur_gt)] = 0\n",
    "        \n",
    "        disp_list.append(cur_disp)\n",
    "        gt_list.append(cur_gt)     \n",
    "        \n",
    "        h,w = cur_disp.shape\n",
    "\n",
    "        cur_upd = np.zeros((h,w))\n",
    "        cur_upd[np.where(cur_disp == 0)] = 1\n",
    "            \n",
    "        cur_keep = np.zeros((h,w))\n",
    "        cur_keep[np.where(cur_upd == 0)] = 1\n",
    "\n",
    "        \n",
    "        keep_list.append(cur_keep)\n",
    "        upd_list.append(cur_upd)    \n",
    "    \n",
    "    total_px_to_upd = 0\n",
    "    for s in range(0,len(disp_list_f)): \n",
    "        \n",
    "        #gets number of 0 and 1 pixels! need 1 pixels (to update)\n",
    "        upd_class,upd_counts = np.unique(upd_list[s], return_counts = True)    \n",
    "        #if upd_counts is not empty\n",
    "        if(len(upd_counts) == 2):\n",
    "            total_px_to_upd = total_px_to_upd + upd_counts[1]\n",
    "    \n",
    "    batch_gt = np.zeros((total_px_to_upd,1))\n",
    "\n",
    "    #count for batch_gt array!\n",
    "    el = 0\n",
    "    nol_count = 0\n",
    "    for c in range(0,len(disp_list_f)):\n",
    "        \n",
    "        print('------------------')\n",
    "        print(disp_list_f[c])\n",
    "        print(gt_list_f[c])\n",
    "        disp = disp_list[c]    \n",
    "        gt = gt_list[c]\n",
    "\n",
    "        keep = keep_list[c]\n",
    "        \n",
    "        disp = disp.copy()\n",
    "        dispT = Variable(Tensor(disp))\n",
    "        \n",
    "        nolabels = np.zeros((disp.shape[0], disp.shape[1]))\n",
    "        \n",
    "        cur_disp_shifted = createShiftPytZero(dispT,chan)\n",
    "        h,w = gt.shape\n",
    "        \n",
    "        #only way to increase performance is to do this for the whole image at once, not per pixel!\n",
    "        #i am sure it is possible but...\n",
    "        for h_ in range(h):\n",
    "            for w_ in range(w):\n",
    "                \n",
    "                if(keep[h_,w_] == 0):\n",
    "                    d_arr = torch.squeeze(cur_disp_shifted[:,h_,w_])\n",
    "                    cur_gt = gt[h_,w_]\n",
    "                    cur_gt = int(np.round(cur_gt))\n",
    "\n",
    "                    gt_label = findGTInDispArrSingle(d_arr, cur_gt, 0)  \n",
    "                    if(gt_label == -1):\n",
    "                        gt_label = findGTInDispArrSingle(d_arr, cur_gt, 1)\n",
    "                        if(gt_label == -1):\n",
    "                            gt_label = findGTInDispArrSingle(d_arr, cur_gt, -1)                        \n",
    "                            if(gt_label == -1):\n",
    "                                gt_label = findGTInDispArrSingle(d_arr, cur_gt, 2)\n",
    "                                if(gt_label == -1):\n",
    "                                    gt_label = findGTInDispArrSingle(d_arr, cur_gt, -2)                        \n",
    "\n",
    "                    #maybe this is the reason! Maybe there are so many\n",
    "                    #zeros because it does not find the labels?\n",
    "                    #test here with -1!\n",
    "                    if(int(gt[h_,w_]) > 0):\n",
    "                        if(gt_label > -1):\n",
    "                            batch_gt[el,0] = int(gt_label)\n",
    "                            el = el + 1\n",
    "                        else:\n",
    "                            nolabels[h_,w_] = 1\n",
    "                            nol_count = nol_count + 1\n",
    "                            \n",
    "        \n",
    "        folder = gt_list_f[c].replace(gt_list_f[c].split('/')[-1],'')\n",
    "        print(folder)\n",
    "                    \n",
    "        name = gt_list_f[c].split('/')[-1].split('.')[0]\n",
    "        print(folder + name + 'no_labels.png')\n",
    "            \n",
    "        cv2.imwrite(folder + name + 'no_labels.png', nolabels * 255)                 \n",
    "        \n",
    "        nolabel_list.append(nolabels)\n",
    "        print('------------------')\n",
    "    \n",
    "    print(\"nolabel count: {}\".format(nol_count))\n",
    "    del cur_disp_shifted\n",
    "    del disp\n",
    "    del gt\n",
    "    \n",
    "    return batch_gt, nolabel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassWeights(disp_list_f, gt_list_f,chan):\n",
    "    #should be vec with all classes over all disparities!!\n",
    "    gtlabels2count,nolabel_list = getClass(disp_list_f, gt_list_f,chan)\n",
    "    gt_classes, gt_counts = np.unique(gtlabels2count.astype(np.uint8), return_counts = True)\n",
    "    \n",
    "    #TODO: Remove pixels with invalid gt from dataset!!! (probably best to include that in keep, update)\n",
    "    #TODO: RE-VISIT THIS! Does it work?\n",
    "    if(len(gt_classes) < (chan)):\n",
    "        for w_ in range(0,chan):\n",
    "            if(w_ not in gt_classes):\n",
    "                gt_counts = np.insert(gt_counts,w_ , 100000)    \n",
    "    norm_w = []\n",
    "    for w_ in range(0,chan):\n",
    "        cur_w = 1 / gt_counts[w_]\n",
    "        norm_w.append(cur_w)\n",
    "    \n",
    "    \n",
    "    class_weights = torch.FloatTensor(norm_w).cuda()\n",
    "    loss_func = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    \n",
    "    return nolabel_list, loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveClassWeights():\n",
    "    norm_w,nolabel_list = getClassWeights()\n",
    "    with open('mb2021.txt', 'w') as f:\n",
    "        for item in norm_w:\n",
    "            f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestMB(names, updInc, chan, disp_list, gt_list, im_list, out_folder,nr_iter, save):\n",
    "    \n",
    "    avg_two_pe = 0.0\n",
    "    \n",
    "    for i in range(len(disp_list)): \n",
    "        \n",
    "        disp  = disp_list[i]\n",
    "        gt = gt_list[i]\n",
    "        im = im_list[i]\n",
    "        name = names[i]\n",
    "        \n",
    "        h,w = disp.shape\n",
    "        \n",
    "        upd = np.zeros((h,w))\n",
    "        upd[np.where(disp == 0)] = 1\n",
    "            \n",
    "        keep = np.zeros((h,w))\n",
    "        keep[np.where(upd == 0)] = 1\n",
    "        \n",
    "\n",
    "        h,w,c = im.shape\n",
    "        im = np.reshape(im, (c,h, w))\n",
    "        im = im[np.newaxis,...]\n",
    "        imT = Variable(Tensor(im.astype(np.uint8)))\n",
    "\n",
    "        upd = np.zeros((disp.shape[0],disp.shape[1]))\n",
    "        upd[np.where(disp == 0)] = 1\n",
    "\n",
    "        keep = np.zeros((disp.shape[0],disp.shape[1]))\n",
    "        keep[np.where(upd == 0)] = 1\n",
    "\n",
    "        keep_t = disp * keep\n",
    "        \n",
    "        updT = Variable(Tensor(upd.astype(np.float32)))\n",
    "        keepT_t = Variable(Tensor(keep_t.astype(np.float32)))\n",
    "        dispT = Variable(Tensor(disp.astype(np.uint8)))\n",
    "        dispShift = createShiftPytZero(dispT, chan)\n",
    "        \n",
    "        dispShift = dispShift.unsqueeze(0)\n",
    "        \n",
    "        OutT = updInc(dispShift,imT) \n",
    "        OutT = torch.squeeze(OutT)\n",
    "        bs,c,x,y = dispShift.shape\n",
    "\n",
    "        idc_for_updt = torch.argmax(OutT, axis=0).unsqueeze(0)  \n",
    "        pred = torch.gather(np.squeeze(dispShift), 0, idc_for_updt).squeeze()\n",
    "\n",
    "        updT_t = pred * updT\n",
    "\n",
    "        final_outp = keepT_t + updT_t\n",
    "        dispT = final_outp\n",
    "\n",
    "        five_pe, four_pe, three_pe, two_pe, one_pe, pf_pe = calcEPE(dispT.cpu().data.numpy().astype(np.float32), gt.astype(np.float32))\n",
    "        avg_two_pe = two_pe + avg_two_pe   \n",
    "        \n",
    "        if(save == True):\n",
    "            writePFM(out_folder + name + '.pfm', final_outp.cpu().data.numpy().astype(np.float32))\n",
    "            \n",
    "        del dispT\n",
    "        del idc_for_updt\n",
    "        del updT_t\n",
    "        del OutT\n",
    "        del dispShift\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        \n",
    "    avg_two_pe = avg_two_pe / len(disp_list)\n",
    "    return avg_two_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestMBRecurrent(out_folder,nr_iter, save):\n",
    "    \n",
    "    n_list = disp_list_f\n",
    "    avg_five_pe = 0.0\n",
    "    avg_four_pe = 0.0 \n",
    "    avg_three_pe = 0.0 \n",
    "    avg_two_pe = 0.0\n",
    "    avg_one_pe = 0.0\n",
    "    avg_pf_pe = 0.0\n",
    "    nr_samples = len(disp_list_f)\n",
    "    \n",
    "    for i in range(len(disp_list_f)): \n",
    "        \n",
    "        t = time.time()\n",
    "        \n",
    "        disp  = disp_list[i]\n",
    "        gt = gt_list[i]\n",
    "        im = im_list[i]\n",
    "\n",
    "        h,w,c = im.shape\n",
    "        im = np.reshape(im, (c,h, w))\n",
    "        im = im[np.newaxis,...]        \n",
    "        imT = Variable(Tensor(im.astype(np.uint8)))\n",
    "\n",
    "        upd = np.zeros((disp.shape[0],disp.shape[1]))\n",
    "        upd[np.where(disp == 0)] = 1\n",
    "\n",
    "        keep = np.zeros((disp.shape[0],disp.shape[1]))\n",
    "        keep[np.where(upd == 0)] = 1\n",
    "\n",
    "        keep_t = disp * keep\n",
    "        \n",
    "        updT = Variable(Tensor(upd.astype(np.float32)))\n",
    "        keepT_t = Variable(Tensor(keep_t.astype(np.float32)))\n",
    "        dispT = Variable(Tensor(disp.astype(np.uint8)))\n",
    "        \n",
    "        for d in range(0,nr_iter):\n",
    "\n",
    "            dispShift = createShiftPytZero(dispT)\n",
    "            dispShift = dispShift.unsqueeze(0)\n",
    "            \n",
    "            OutT = updInc(dispShift,imT) \n",
    "            OutT = torch.squeeze(OutT)\n",
    "\n",
    "            bs,c,x,y = dispShift.shape\n",
    "\n",
    "            idc_for_updt = torch.argmax(OutT, axis=0).unsqueeze(0)  \n",
    "            pred = torch.gather(np.squeeze(dispShift), 0, idc_for_updt).squeeze()\n",
    "            \n",
    "            updT_t = pred * updT\n",
    "            \n",
    "            final_outp = keepT_t + updT_t\n",
    "            dispT = final_outp\n",
    "            \n",
    "            elapsed = time.time() - t\n",
    "            print (\"Time: {}\".format(elapsed))\n",
    "            \n",
    "            del OutT\n",
    "            del idc_for_updt\n",
    "            del dispShift\n",
    "            torch.cuda.empty_cache()  \n",
    "            \n",
    "            \n",
    "        disp_arr = dispT.cpu().data.numpy().astype(np.float32)\n",
    "        disp_arr = cv2.medianBlur(disp_arr,5)\n",
    "\n",
    "        five_pe, four_pe, three_pe, two_pe, one_pe, pf_pe = calcEPE(disp_arr, gt.astype(np.float32))\n",
    "        \n",
    "        print(\"2-PE: {}\".format(two_pe))\n",
    "        \n",
    "        avg_five_pe = avg_five_pe + five_pe\n",
    "        avg_four_pe = avg_four_pe +  four_pe\n",
    "        avg_three_pe = avg_three_pe + three_pe\n",
    "        avg_two_pe = avg_two_pe + two_pe\n",
    "        avg_one_pe = avg_one_pe + one_pe\n",
    "        avg_pf_pe = avg_pf_pe + pf_pe        \n",
    "        \n",
    "        name = n_list[i].split('/')[-1].replace('_s.pfm', '')\n",
    "        if(save == True):\n",
    "            writePFM(out_folder + name +'.pfm' , disp_arr)\n",
    "        \n",
    "        f= open(out_folder + name +'.txt',\"w+\")   \n",
    "        f.write(\"runtime \" + str(elapsed))\n",
    "            \n",
    "    avg_four_pe = avg_four_pe / nr_samples\n",
    "    avg_two_pe = avg_two_pe / nr_samples\n",
    "    avg_one_pe = avg_one_pe / nr_samples\n",
    "    avg_pf_pe = avg_pf_pe / nr_samples\n",
    "    \n",
    "    print(\"4-PE: {}\".format(avg_four_pe))\n",
    "    print(\"2-PE: {}\".format(avg_two_pe))\n",
    "    print(\"1-PE: {}\".format(avg_one_pe))\n",
    "    print(\"0.5-PE: {}\".format(avg_pf_pe))\n",
    "    return avg_two_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBatch(chan, gt_list, im_list, patch_size, nr_ex, disp_list, nolabel_list):\n",
    "    \n",
    "    batch_x = Variable(Tensor(np.zeros((nr_ex,chan,patch_size,patch_size))))\n",
    "    \n",
    "    batch_gt = np.zeros((nr_ex,patch_size,patch_size))\n",
    "    batch_im = np.zeros((nr_ex,3,patch_size,patch_size))\n",
    "    \n",
    "    ridx = np.random.randint(0,len(disp_list),1)\n",
    "        \n",
    "    disp = disp_list[ridx[0]]    \n",
    "    gt = gt_list[ridx[0]]\n",
    "    \n",
    "    im = im_list[ridx[0]]\n",
    "    h,w,c = im.shape\n",
    "    im = np.reshape(im, (c,h, w))\n",
    "    \n",
    "    h,w = disp.shape\n",
    "    upd = np.zeros((h,w))\n",
    "    upd[np.where(disp == 0)] = 1\n",
    "\n",
    "    keep = np.zeros((h,w))\n",
    "    keep[np.where(upd == 0)] = 1\n",
    "\n",
    "        \n",
    "    nolabel = nolabel_list[ridx[0]]\n",
    "    dispT = Variable(Tensor(disp.astype(np.uint8)))\n",
    "    \n",
    "    cur_disp_shifted = createShiftPytZero(dispT,chan)\n",
    "    \n",
    "    ps_h = int(patch_size/2)\n",
    "\n",
    "    h,w = gt.shape\n",
    "    \n",
    "    for el in range(nr_ex):\n",
    "        #get random position\n",
    "        c,h,w = cur_disp_shifted.shape\n",
    "        r_h = 0\n",
    "        r_w = 0\n",
    "        d = 0\n",
    "        \n",
    "        r_h = random.sample(range(0,h), 1)\n",
    "        r_w = random.sample(range(0,w),1)\n",
    "        d_arr = torch.squeeze(cur_disp_shifted[:,r_h[0]-ps_h:r_h[0]+(ps_h+1),r_w[0]-ps_h:r_w[0]+(ps_h+1)])\n",
    "        cur_gt = gt[r_h[0]-ps_h:r_h[0]+(ps_h+1),r_w[0]-ps_h:r_w[0]+(ps_h+1)]\n",
    "        cur_gt = cur_gt.astype(np.uint8)\n",
    "        \n",
    "        i = 0\n",
    "        \n",
    "        while(True): \n",
    "            r_h = random.sample(range(0,h), 1)\n",
    "            r_w = random.sample(range(0,w), 1)\n",
    "            i = i + 1\n",
    "            if(r_h[0]-ps_h > 0):\n",
    "              if(r_h[0]+ps_h < h):\n",
    "                if(r_w[0]-ps_h > 0):\n",
    "                  if(r_w[0]+ps_h < w):\n",
    "                    if(int(gt[r_h[0],r_w[0]]) > 0):\n",
    "                        if(keep[r_h[0],r_w[0]] == 0):\n",
    "                            if(nolabel[r_h[0],r_w[0]] == 0):\n",
    "                          \n",
    "                                d_arr = torch.squeeze(cur_disp_shifted[:,r_h[0]-ps_h:r_h[0]+(ps_h+1),r_w[0]-ps_h:r_w[0]+(ps_h+1)])\n",
    "                                cur_gt = gt[r_h[0]-ps_h:r_h[0]+(ps_h+1),r_w[0]-ps_h:r_w[0]+(ps_h+1)]\n",
    "                                cur_gt = cur_gt.astype(np.uint8)\n",
    "                                gt_label = findGTInDispArr(chan, d_arr.cpu().data.numpy().astype(np.float32), cur_gt, 0)\n",
    "                                break\n",
    "        \n",
    "        cur_disp = cur_disp_shifted[:,r_h[0]-ps_h:r_h[0]+(ps_h+1),r_w[0]-ps_h:r_w[0]+(ps_h+1)]\n",
    "        batch_x[el,:,:,:] = cur_disp       \n",
    "        batch_gt[el,:,:] = gt_label\n",
    "\n",
    "        batch_im[el,:,:,:] = im[:,r_h[0]-ps_h:r_h[0]+(ps_h+1),r_w[0]-ps_h:r_w[0]+(ps_h+1)]\n",
    "        \n",
    "    return batch_x, batch_gt, batch_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nolabel_list, loss_func = getClassWeights(disp_list_f, gt_list_f,chan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(dataset == 'MB' or dataset == 'MB2021'):\n",
    "    disp_list, gt_list, im_list, names = loadMB(disp_list_f, gt_list_f, im_left_list_f)\n",
    "if(dataset == 'Kitti2012'):\n",
    "    disp_list, gt_list, im_list, names = loadKitti2012(disp_list_f, gt_list_f, im_left_list_f)\n",
    "if(dataset == 'Kitti2015'):\n",
    "    disp_list, gt_list, im_list, names = loadKitti2015(disp_list_f, gt_list_f, im_left_list_f)\n",
    "if(dataset == 'ETH'):\n",
    "    disp_list, gt_list, im_list, names = loadKitti2015(disp_list_f, gt_list_f, im_left_list_f)\n",
    "\n",
    "\n",
    "\n",
    "optimizer_G = optim.Adam(updInc.parameters(),  lr)\n",
    "\n",
    "best_two_pe = 100\n",
    "\n",
    "dispShift, gt, im = getBatch(chan, gt_list, im_list, patch_size, batch_size, disp_list, nolabel_list)\n",
    "\n",
    "imT = Variable(Tensor(im.astype(np.uint8)))\n",
    "gtT = Variable(LTensor(gt.astype(np.uint8)))\n",
    "\n",
    "\n",
    "for i in range(nr_epochs):\n",
    "\n",
    "    #reset gradients\n",
    "    optimizer_G.zero_grad()\n",
    "    OutT = updInc(dispShift,imT) \n",
    "\n",
    "    loss = loss_func(OutT, gtT)\n",
    "    loss = torch.mean(loss)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer_G.step()\n",
    "\n",
    "    save = 1000\n",
    "\n",
    "    if(i % save == 0):            \n",
    "\n",
    "        print(\"EPOCH: {} CE-loss: {}\".format(i,loss))  \n",
    "        #probably does backprop!\n",
    "        #avg_two_pe = TestMBRecurrent(out_folder,i, False)\n",
    "        avg_two_pe = TestMB(names, updInc, chan, disp_list, gt_list, im_list, out_folder,1, False)\n",
    "\n",
    "        print(\"2-PE Depth-Completion: {}\".format(avg_two_pe))\n",
    "\n",
    "        if(avg_two_pe < best_two_pe):\n",
    "\n",
    "            avg_two_pe = TestMB(names, updInc, chan, disp_list, gt_list, im_list, out_folder,i, True)\n",
    "            print(colored('------------------', 'green', attrs=['bold']))                         \n",
    "            print(colored('NEW PB network: {}'.format(avg_two_pe), 'green', attrs=['bold']))  \n",
    "            print(colored('------------------', 'green', attrs=['bold']))                         \n",
    "\n",
    "            best_two_pe = avg_two_pe\n",
    "            torch.save(updInc.state_dict(), w_folder + model_name + '_%06i' %(i) + 'e%06f' %(best_two_pe)) \n",
    "\n",
    "        dispShift, gt, im = getBatch(chan, gt_list, im_list, patch_size, batch_size, disp_list, nolabel_list)\n",
    "\n",
    "        imT = Variable(Tensor(im.astype(np.uint8)))\n",
    "        gtT = Variable(LTensor(gt.astype(np.uint8)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
