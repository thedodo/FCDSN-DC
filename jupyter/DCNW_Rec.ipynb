{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3621,
     "status": "ok",
     "timestamp": 1615907226539,
     "user": {
      "displayName": "Dominik Hirner",
      "photoUrl": "",
      "userId": "16020349886697963223"
     },
     "user_tz": -60
    },
    "id": "yjHCuCekchKI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "from numpy import inf\n",
    "import cv2\n",
    "import re\n",
    "from torch import optim\n",
    "\n",
    "import time\n",
    "import itertools\n",
    "import timeit\n",
    "import argparse\n",
    "import imutils\n",
    "from PIL import Image\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models\n",
    "\n",
    "import skimage\n",
    "import numpy.matlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import progressbar\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "import random\n",
    "from termcolor import colored\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor = torch.cuda.FloatTensor\n",
    "LTensor = torch.cuda.LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.backends.cudnn.benchmark = True\n",
    "#torch.autograd.set_detect_anomaly(False)\n",
    "#torch.autograd.profiler.profile(False)\n",
    "#torch.autograd.profiler.emit_nvtx(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'MB2021'\n",
    "\n",
    "if(dataset == 'MB2021'):\n",
    "    cfg_file = '/media/HDD/ICPR-AblationStudies/fillOld_TrainedFill/config/MB2021.cfg'\n",
    "if(dataset == 'MB'):\n",
    "    cfg_file = '/media/HDD/ICPR-AblationStudies/fillOld_TrainedFill/config/MB.cfg'\n",
    "if(dataset == 'MBEval'):\n",
    "    cfg_file = '/media/HDD/ICPR-AblationStudies/fillOld_TrainedFill/config/MBEval.cfg'\n",
    "if(dataset == 'Kitti2012'):\n",
    "    cfg_file = '/media/HDD/ICPR-AblationStudies/fillOld_TrainedFill/config/Kitti2012.cfg'\n",
    "if(dataset == 'Kitti2012Test'):\n",
    "    cfg_file = '/media/HDD/ICPR-AblationStudies/fillOld_TrainedFill/config/Kitti2012Test.cfg'\n",
    "\n",
    "if(dataset == 'Kitti2015'):\n",
    "    cfg_file = '/media/HDD/ICPR-AblationStudies/fillOld_TrainedFill/config/Kitti2015.cfg'\n",
    "\n",
    "if(dataset == 'Kitti2015Test'):\n",
    "    cfg_file = '/media/HDD/ICPR-AblationStudies/fillOld_TrainedFill/config/Kitti2015Test.cfg'\n",
    "\n",
    "if(dataset == 'ETH3D'):\n",
    "    cfg_file = '/media/HDD/ICPR-AblationStudies/fillOld_TrainedFill/config/ETH3D.cfg'\n",
    "if(dataset == 'ETH3DTest'):\n",
    "    cfg_file = '/media/HDD/ICPR-AblationStudies/fillOld_TrainedFill/config/ETH3DTest.cfg'\n",
    "if(dataset == 'Flickr'):\n",
    "    cfg_file = '/media/HDD/ICPR-AblationStudies/fillOld_TrainedFill/config/Flickr.cfg'\n",
    "if(dataset == 'Holopix'):\n",
    "    cfg_file = '/media/HDD/ICPR-AblationStudies/fillOld_TrainedFill/config/Holopix.cfg'\n",
    "if(dataset == 'Sat'):\n",
    "    cfg_file = '/media/HDD/ICPR-AblationStudies/fillOld_TrainedFill/config/Sat.cfg'\n",
    "#if(dataset == 'Sintel'):\n",
    "#    cfg_file = '/media/HDD/FCDSN-DC/config/ETH3D.cfg'\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(cfg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = int(config['PARAM']['patch_size'])\n",
    "ps_h = int(patch_size/2)\n",
    "nr_epochs = int(config['PARAM']['nr_epochs'])\n",
    "batch_size = int(config['PARAM']['batch_size'])\n",
    "model_name = config['PARAM']['model_name']\n",
    "s_range = int(config['PARAM']['s_range'])\n",
    "chan = int(config['PARAM']['chan'])\n",
    "\n",
    "train = config.getboolean('PARAM','train')\n",
    "disp_list = config['PARAM']['disp_list']\n",
    "\n",
    "gt_list = config['PARAM']['gt_list']\n",
    "im_left_list = config['PARAM']['im_left_list']\n",
    "\n",
    "out_folder = config['PARAM']['out_folder']\n",
    "w_folder = config['PARAM']['w_folder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#im_left_list broken!!! has upd and mask also!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#im_left_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config_print = True\n",
    "\n",
    "if(config_print):\n",
    "    \n",
    "    print(\"patch_size: \" ,patch_size)\n",
    "    print(\"ps_h: \" ,ps_h)\n",
    "    print(\"nr_epochs: \" ,nr_epochs)\n",
    "    print(\"batch_size: \" ,batch_size)\n",
    "    print(\"model_name: \" ,model_name)\n",
    "    print(\"s_range: \" ,s_range)\n",
    "    print(\"Patch size: \", patch_size)\n",
    "    print(\"chan: \", chan)\n",
    "    print(\"train: \" ,train)\n",
    "    print(\"disp_list: \" ,disp_list)\n",
    "    print(\"gt_list: \" ,gt_list)\n",
    "    print(\"out_folder: \" ,out_folder)\n",
    "    print(\"w_folder: \" ,w_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_list = glob.glob(gt_list)\n",
    "im_left_list = glob.glob(im_left_list)\n",
    "\n",
    "gt_list = sorted(gt_list)\n",
    "im_left_list = sorted(im_left_list)\n",
    "\n",
    "gt_list_f = gt_list\n",
    "im_left_list_f = im_left_list\n",
    "\n",
    "disp_list_f = glob.glob(disp_list)\n",
    "disp_list_f = sorted(disp_list_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3615,
     "status": "ok",
     "timestamp": 1615907226546,
     "user": {
      "displayName": "Dominik Hirner",
      "photoUrl": "",
      "userId": "16020349886697963223"
     },
     "user_tz": -60
    },
    "id": "E2-XTbV6chKK"
   },
   "outputs": [],
   "source": [
    "def readPFM(file):\n",
    "    file = open(file, 'rb')\n",
    "\n",
    "    color = None\n",
    "    width = None\n",
    "    height = None\n",
    "    scale = None\n",
    "    endian = None\n",
    "\n",
    "    header = file.readline().decode('utf-8').rstrip()\n",
    "    if header == 'PF':\n",
    "        color = True\n",
    "    elif header == 'Pf':\n",
    "        color = False\n",
    "    else:\n",
    "        raise Exception('Not a PFM file.')\n",
    "\n",
    "    dim_match = re.match(r'^(\\d+)\\s(\\d+)\\s$', file.readline().decode('utf-8'))\n",
    "    if dim_match:\n",
    "        width, height = map(int, dim_match.groups())\n",
    "    else:\n",
    "        raise Exception('Malformed PFM header.')\n",
    "\n",
    "    scale = float(file.readline().decode('utf-8').rstrip())\n",
    "    if scale < 0:  # little-endian\n",
    "        endian = '<'\n",
    "        scale = -scale\n",
    "    else:\n",
    "        endian = '>'  # big-endian\n",
    "\n",
    "    data = np.fromfile(file, endian + 'f')\n",
    "    shape = (height, width, 3) if color else (height, width)\n",
    "\n",
    "    data = np.reshape(data, shape)\n",
    "    data = np.flipud(data)\n",
    "    return data, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3612,
     "status": "ok",
     "timestamp": 1615907226546,
     "user": {
      "displayName": "Dominik Hirner",
      "photoUrl": "",
      "userId": "16020349886697963223"
     },
     "user_tz": -60
    },
    "id": "Y90O8NFgchKL"
   },
   "outputs": [],
   "source": [
    "def writePFM(file, image, scale=1):\n",
    "    file = open(file, 'wb')\n",
    "\n",
    "    color = None\n",
    "\n",
    "    if image.dtype.name != 'float32':\n",
    "        raise Exception('Image dtype must be float32.')\n",
    "\n",
    "    image = np.flipud(image)\n",
    "\n",
    "    if len(image.shape) == 3 and image.shape[2] == 3:  # color image\n",
    "        color = True\n",
    "    elif len(image.shape) == 2 or len(image.shape) == 3 and image.shape[2] == 1:  # greyscale\n",
    "        color = False\n",
    "    else:\n",
    "        raise Exception('Image must have H x W x 3, H x W x 1 or H x W dimensions.')\n",
    "\n",
    "    file.write('PF\\n'.encode() if color else 'Pf\\n'.encode())\n",
    "    file.write('%d %d\\n'.encode() % (image.shape[1], image.shape[0]))\n",
    "\n",
    "    endian = image.dtype.byteorder\n",
    "\n",
    "    if endian == '<' or endian == '=' and sys.byteorder == 'little':\n",
    "        scale = -scale\n",
    "\n",
    "    file.write('%f\\n'.encode() % scale)\n",
    "\n",
    "    image.tofile(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_conv_st1 = 70\n",
    "\n",
    "class UpdateInconsNW(nn.Module):\n",
    "    def __init__(self,img_ch=chan):\n",
    "        super(UpdateInconsNW,self).__init__()\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "        self.Conv1 = nn.Conv2d(img_ch, n_conv_st1, kernel_size = 3,stride=1,padding = 1,dilation = 1, bias=True)\n",
    "        self.Conv2 = nn.Conv2d(n_conv_st1, n_conv_st1, kernel_size=3,stride=1,padding = 1,dilation = 1, bias=True)        \n",
    "        self.Conv3 = nn.Conv2d(n_conv_st1 + 3, img_ch, kernel_size=3,stride=1,padding = 1,dilation = 1, bias=True)\n",
    "        \n",
    "        \n",
    "    def forward(self,x_in, im):\n",
    "        \n",
    "        x1 = self.Conv1(x_in)\n",
    "        x1 = self.act(x1)\n",
    "                        \n",
    "        x2 = self.Conv2(x1)\n",
    "        x2 = self.act(x2)\n",
    "                \n",
    "        x3im = torch.cat((x2,im),axis = 1)\n",
    "        \n",
    "        x3 = self.Conv3(x3im)\n",
    "        x3 = self.softmax(x3)\n",
    "        \n",
    "        return x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5421,
     "status": "ok",
     "timestamp": 1615907228363,
     "user": {
      "displayName": "Dominik Hirner",
      "photoUrl": "",
      "userId": "16020349886697963223"
     },
     "user_tz": -60
    },
    "id": "MRpUoV9_chKN",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "updInc = UpdateInconsNW()\n",
    "updInc = updInc.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upd_nw_params = sum(p.numel() for p in updInc.parameters() if p.requires_grad)\n",
    "print(\"Depth-Completion Network: \" ,upd_nw_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcEPE(disp, gt_fn):\n",
    "    \n",
    "    gt = gt_fn\n",
    "\n",
    "    gt[np.where(gt == np.inf)] = -100\n",
    "    \n",
    "    mask = gt > 0\n",
    "    \n",
    "    disp = np.squeeze(disp)\n",
    "    disp = disp[mask]\n",
    "    gt = gt[mask]\n",
    "\n",
    "    nr_px = len(gt)\n",
    "\n",
    "    abs_error_im = np.abs(disp - gt)\n",
    "\n",
    "    five_pe = (float(np.count_nonzero(abs_error_im >= 5.0) ) / nr_px) * 100.0  \n",
    "    four_pe = (float(np.count_nonzero(abs_error_im >= 4.0) ) / nr_px) * 100.0  \n",
    "    three_pe = (float(np.count_nonzero(abs_error_im >= 3.0) ) / nr_px) * 100.0  \n",
    "    two_pe = (float(np.count_nonzero(abs_error_im >= 2.0) ) / nr_px) * 100.0        \n",
    "    one_pe = (float(np.count_nonzero(abs_error_im >= 1.0) ) / nr_px) * 100.0        \n",
    "    pf_pe = (float(np.count_nonzero(abs_error_im >= 0.5) ) / nr_px) * 100.0  \n",
    "        \n",
    "    return five_pe, four_pe, three_pe, two_pe, one_pe, pf_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11923,
     "status": "ok",
     "timestamp": 1615907234922,
     "user": {
      "displayName": "Dominik Hirner",
      "photoUrl": "",
      "userId": "16020349886697963223"
     },
     "user_tz": -60
    },
    "id": "nn4Jll4pmEnk"
   },
   "outputs": [],
   "source": [
    "def findGTInDispArr(arr, gt, offset):\n",
    "    c,w,h = arr.shape\n",
    "    first_arr = np.zeros((w,h))\n",
    "    \n",
    "    #TO SEE HOW MANY ARE STILL NOT USABLE!!!\n",
    "    first_arr = first_arr * -1\n",
    "    \n",
    "    for w_ in range(0,w-1):\n",
    "      for h_ in range(0,h-1):\n",
    "        found = 0\n",
    "        for i in range(0,chan):\n",
    "            if (int(arr[i,w_,h_]) == (int(gt[w_,h_])+offset)):\n",
    "                first_arr[w_,h_] = i\n",
    "                found = 1\n",
    "                break\n",
    "        if(found == 0):\n",
    "            for i in range(0,chan):\n",
    "                if (int(arr[i,w_,h_]) == (int(gt[w_,h_])+offset+1)):\n",
    "                    first_arr[w_,h_] = i\n",
    "                    found = 1\n",
    "                    break\n",
    "        if(found == 0):\n",
    "            for i in range(0,chan):\n",
    "                if (int(arr[i,w_,h_]) == (int(gt[w_,h_])+offset-1)):\n",
    "                    first_arr[w_,h_] = i\n",
    "                    found = 1\n",
    "                    break\n",
    "        if(found == 0):\n",
    "            for i in range(0,chan):\n",
    "                if (int(arr[i,w_,h_]) == (int(gt[w_,h_])+offset+2)):\n",
    "                    first_arr[w_,h_] = i\n",
    "                    found = 1\n",
    "                    break\n",
    "        if(found == 0):\n",
    "            for i in range(0,chan):\n",
    "                if (int(arr[i,w_,h_]) == (int(gt[w_,h_])+offset-2)):\n",
    "                    first_arr[w_,h_] = i\n",
    "                    found = 1\n",
    "                    break\n",
    "            \n",
    "    return first_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findGTInDispArrSingle(arr, gt, offset):\n",
    "    \n",
    "    first = -1\n",
    "    #this loop could probably be sped up right?\n",
    "    for i in range(0,len(arr)):\n",
    "        if (int(arr[i]) == (int(gt)+offset)):\n",
    "            first = i\n",
    "            break\n",
    "            \n",
    "    return first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadKitti2012():\n",
    "\n",
    "    im_list = []\n",
    "    gt_list = []\n",
    "    disp_list = []\n",
    "    keep_list = []\n",
    "    update_list = []\n",
    "    #nolabel_list = []    \n",
    "    \n",
    "    for i in range(0,len(disp_list_f)):\n",
    "        \n",
    "        cur_im = cv2.imread(im_left_list_f[i])\n",
    "        #normalize\n",
    "        cur_im = (cur_im - np.min(cur_im)) / (np.max(cur_im) - np.min(cur_im))\n",
    "        cur_disp, _ = readPFM(disp_list_f[i])\n",
    "        cur_gt, _ = readPFM(gt_list_f[i])\n",
    "        \n",
    "        cur_disp[np.isnan(cur_disp)] = 0\n",
    "        cur_disp[np.isinf(cur_disp)] = 0\n",
    "\n",
    "        cur_gt[np.isnan(cur_gt)] = 0\n",
    "        cur_gt[np.isinf(cur_gt)] = 0\n",
    "        \n",
    "        cur_keep = cv2.imread(keepMask_list_f[i])\n",
    "        cur_upd = cv2.imread(updateMask_list_f[i])\n",
    "        #cur_nolabel = cv2.imread(nolabel_list_f[i])\n",
    "        \n",
    "        cur_keep = np.mean(cur_keep, axis=2)\n",
    "        cur_upd = np.mean(cur_upd, axis=2)\n",
    "        #cur_nolabel = np.mean(cur_nolabel, axis=2)\n",
    "\n",
    "        cur_keep = cur_keep / 255\n",
    "        cur_upd = cur_upd / 255            \n",
    "        #cur_nolabel = cur_nolabel / 255\n",
    "        \n",
    "        #print(cur_im.shape)\n",
    "        #print(cur_disp.shape)\n",
    "        im_list.append(cur_im)\n",
    "        gt_list.append(cur_gt)\n",
    "        disp_list.append(cur_disp)\n",
    "        keep_list.append(cur_keep)\n",
    "        update_list.append(cur_upd)\n",
    "        #nolabel_list.append(cur_nolabel)\n",
    "\n",
    "    return disp_list, gt_list, keep_list, update_list, im_list#, nolabel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadKitti2015():\n",
    "\n",
    "    im_list = []\n",
    "    gt_list = []\n",
    "    disp_list = []\n",
    "    keep_list = []\n",
    "    update_list = []\n",
    "    nolabel_list = []    \n",
    "    \n",
    "    for i in range(0,len(disp_list_f)):\n",
    "        \n",
    "        cur_im = cv2.imread(im_left_list_f[i])\n",
    "        \n",
    "        #normalize\n",
    "        cur_im = (cur_im - np.min(cur_im)) / (np.max(cur_im) - np.min(cur_im))\n",
    "        \n",
    "        cur_disp, _ = readPFM(disp_list_f[i])\n",
    "        cur_gt, _ = readPFM(gt_list_f[i])\n",
    "        \n",
    "        cur_disp[np.isnan(cur_disp)] = 0\n",
    "        cur_disp[np.isinf(cur_disp)] = 0\n",
    "\n",
    "        cur_gt[np.isnan(cur_gt)] = 0\n",
    "        cur_gt[np.isinf(cur_gt)] = 0\n",
    "        \n",
    "        cur_keep = cv2.imread(keepMask_list_f[i])\n",
    "        cur_upd = cv2.imread(updateMask_list_f[i])\n",
    "        \n",
    "        cur_keep = np.mean(cur_keep, axis=2)\n",
    "        cur_upd = np.mean(cur_upd, axis=2)\n",
    "\n",
    "        cur_keep = cur_keep / 255\n",
    "        cur_upd = cur_upd / 255            \n",
    "        \n",
    "        im_list.append(cur_im)\n",
    "        gt_list.append(cur_gt)\n",
    "        disp_list.append(cur_disp)\n",
    "        keep_list.append(cur_keep)\n",
    "        update_list.append(cur_upd)\n",
    "\n",
    "    return disp_list, gt_list, keep_list, update_list, im_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadMB():\n",
    "    \n",
    "    disp_list = []\n",
    "    gt_list = []\n",
    "    im_list = []\n",
    "          \n",
    "    for i in range(0,len(disp_list_f)):\n",
    "        \n",
    "        cur_disp, _ = readPFM(disp_list_f[i])\n",
    "        cur_gt, _ = readPFM(gt_list_f[i])\n",
    "        \n",
    "        cur_disp[np.isnan(cur_disp)] = 0\n",
    "        cur_disp[np.isinf(cur_disp)] = 0\n",
    "\n",
    "        cur_gt[np.isnan(cur_gt)] = 0\n",
    "        cur_gt[np.isinf(cur_gt)] = 0\n",
    "                    \n",
    "        cur_im = cv2.imread(im_left_list_f[i])\n",
    "        cur_im = (cur_im - np.min(cur_im)) / (np.max(cur_im) - np.min(cur_im))\n",
    "        \n",
    "        disp_list.append(cur_disp)\n",
    "        gt_list.append(cur_gt)\n",
    "        im_list.append(cur_im)\n",
    "        \n",
    "    return disp_list, gt_list,im_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadMBEval():\n",
    "    \n",
    "    disp_list = []\n",
    "    gt_list = []\n",
    "    keep_list = []\n",
    "    upd_list = []\n",
    "    im_list = []\n",
    "          \n",
    "    for i in range(0,len(disp_list_f)):\n",
    "        \n",
    "        cur_disp, _ = readPFM(disp_list_f[i])\n",
    "        cur_gt, _ = readPFM(gt_list_f[i])\n",
    "        \n",
    "        cur_disp[np.isnan(cur_disp)] = 0\n",
    "        cur_disp[np.isinf(cur_disp)] = 0\n",
    "\n",
    "        cur_gt[np.isnan(cur_gt)] = 0\n",
    "        cur_gt[np.isinf(cur_gt)] = 0\n",
    "        \n",
    "        cur_keep = cv2.imread(keepMask_list_f[i])\n",
    "        cur_upd = cv2.imread(updateMask_list_f[i])\n",
    "        \n",
    "        cur_keep = np.mean(cur_keep, axis=2)\n",
    "        cur_upd = np.mean(cur_upd, axis=2)        \n",
    "\n",
    "        cur_keep = cur_keep / 255\n",
    "        cur_upd = cur_upd / 255   \n",
    "            \n",
    "        cur_im = cv2.imread(im_left_list_f[i])\n",
    "        \n",
    "        #normalize\n",
    "        #cur_im = np.mean(cur_im,axis=2)\n",
    "        cur_im = (cur_im - np.min(cur_im)) / (np.max(cur_im) - np.min(cur_im))\n",
    "\n",
    "        #cur_im[:,:,0] = (cur_im[:,:,0] - np.min(cur_im[:,:,0])) / (np.max(cur_im[:,:,0]) - np.min(cur_im[:,:,0]))\n",
    "        #cur_im[:,:,1] = (cur_im[:,:,1] - np.min(cur_im[:,:,1])) / (np.max(cur_im[:,:,1]) - np.min(cur_im[:,:,1]))\n",
    "        #cur_im[:,:,2] = (cur_im[:,:,2] - np.min(cur_im[:,:,2])) / (np.max(cur_im[:,:,2]) - np.min(cur_im[:,:,2]))\n",
    "\n",
    "        #im = np.mean(im, axis=2)\n",
    "        \n",
    "        disp_list.append(cur_disp)\n",
    "        gt_list.append(cur_gt)\n",
    "        keep_list.append(cur_keep)\n",
    "        upd_list.append(cur_upd)\n",
    "        im_list.append(cur_im)\n",
    "        \n",
    "    return disp_list, gt_list, keep_list, upd_list,im_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSintel():\n",
    "\n",
    "    im_list = []\n",
    "    gt_list = []\n",
    "    disp_list = []\n",
    "    keep_list = []\n",
    "    update_list = []\n",
    "    \n",
    "    for i in range(0,len(disp_list_f)):\n",
    "        \n",
    "        cur_im = cv2.imread(im_left_list_f[i])\n",
    "        \n",
    "        #normalize\n",
    "        cur_im = (cur_im - np.min(cur_im)) / (np.max(cur_im) - np.min(cur_im))\n",
    "        \n",
    "        cur_disp, _ = readPFM(disp_list_f[i])\n",
    "        cur_gt, _ = readPFM(gt_list_f[i])\n",
    "        \n",
    "        cur_disp[np.isnan(cur_disp)] = 0\n",
    "        cur_disp[np.isinf(cur_disp)] = 0\n",
    "\n",
    "        cur_gt[np.isnan(cur_gt)] = 0\n",
    "        cur_gt[np.isinf(cur_gt)] = 0\n",
    "        \n",
    "        cur_keep = cv2.imread(keepMask_list_f[i])\n",
    "        cur_upd = cv2.imread(updateMask_list_f[i])\n",
    "        \n",
    "        cur_keep = np.mean(cur_keep, axis=2)\n",
    "        cur_upd = np.mean(cur_upd, axis=2)\n",
    "\n",
    "        cur_keep = cur_keep / 255\n",
    "        cur_upd = cur_upd / 255            \n",
    "        \n",
    "        im_list.append(cur_im)\n",
    "        gt_list.append(cur_gt)\n",
    "        disp_list.append(cur_disp)\n",
    "        keep_list.append(cur_keep)\n",
    "        update_list.append(cur_upd)\n",
    "\n",
    "    return disp_list, gt_list, keep_list, update_list, im_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadKitti2012Test():\n",
    "\n",
    "    im_list = []\n",
    "    disp_list = []\n",
    "    keep_list = []\n",
    "    update_list = []\n",
    "    \n",
    "    for i in range(0,len(disp_list_f)):\n",
    "        \n",
    "        cur_im = cv2.imread(im_left_list_f[i])        \n",
    "        \n",
    "        cur_disp, _ = readPFM(disp_list_f[i])\n",
    "        \n",
    "        cur_disp[np.isnan(cur_disp)] = 0\n",
    "        cur_disp[np.isinf(cur_disp)] = 0\n",
    "        \n",
    "        cur_keep = cv2.imread(keepMask_list_f[i])\n",
    "        cur_upd = cv2.imread(updateMask_list_f[i])\n",
    "        \n",
    "        cur_keep = np.mean(cur_keep, axis=2)\n",
    "        cur_upd = np.mean(cur_upd, axis=2)\n",
    "\n",
    "        cur_keep = cur_keep / 255\n",
    "        cur_upd = cur_upd / 255            \n",
    "        \n",
    "        im_list.append(cur_im)\n",
    "        disp_list.append(cur_disp)\n",
    "        keep_list.append(cur_keep)\n",
    "        update_list.append(cur_upd)        \n",
    "\n",
    "    return disp_list, keep_list, update_list, im_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadKitti2015Test():\n",
    "\n",
    "    im_list = []\n",
    "    disp_list = []\n",
    "    keep_list = []\n",
    "    update_list = []\n",
    "    \n",
    "    for i in range(0,len(disp_list_f)):\n",
    "        \n",
    "        cur_im = cv2.imread(im_left_list_f[i])        \n",
    "        \n",
    "        cur_disp, _ = readPFM(disp_list_f[i])\n",
    "        \n",
    "        cur_disp[np.isnan(cur_disp)] = 0\n",
    "        cur_disp[np.isinf(cur_disp)] = 0\n",
    "        \n",
    "        cur_keep = cv2.imread(keepMask_list_f[i])\n",
    "        cur_upd = cv2.imread(updateMask_list_f[i])\n",
    "        \n",
    "        cur_keep = np.mean(cur_keep, axis=2)\n",
    "        cur_upd = np.mean(cur_upd, axis=2)\n",
    "\n",
    "        cur_keep = cur_keep / 255\n",
    "        cur_upd = cur_upd / 255            \n",
    "        \n",
    "        im_list.append(cur_im)\n",
    "        disp_list.append(cur_disp)\n",
    "        keep_list.append(cur_keep)\n",
    "        update_list.append(cur_upd)        \n",
    "\n",
    "    return disp_list, keep_list, update_list, im_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadETH3DTest():\n",
    "\n",
    "    im_list = []\n",
    "    disp_list = []\n",
    "    keep_list = []\n",
    "    update_list = []\n",
    "    \n",
    "    for i in range(0,len(disp_list_f)):\n",
    "        \n",
    "        cur_im = cv2.imread(im_left_list_f[i])        \n",
    "        \n",
    "        cur_disp, _ = readPFM(disp_list_f[i])\n",
    "        \n",
    "        cur_disp[np.isnan(cur_disp)] = 0\n",
    "        cur_disp[np.isinf(cur_disp)] = 0\n",
    "        \n",
    "        cur_keep = cv2.imread(keepMask_list_f[i])\n",
    "        cur_upd = cv2.imread(updateMask_list_f[i])\n",
    "        \n",
    "        cur_keep = np.mean(cur_keep, axis=2)\n",
    "        cur_upd = np.mean(cur_upd, axis=2)\n",
    "\n",
    "        cur_keep = cur_keep / 255\n",
    "        cur_upd = cur_upd / 255            \n",
    "        \n",
    "        im_list.append(cur_im)\n",
    "        disp_list.append(cur_disp)\n",
    "        keep_list.append(cur_keep)\n",
    "        update_list.append(cur_upd)        \n",
    "\n",
    "    return disp_list, keep_list, update_list, im_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadETH3D():\n",
    "\n",
    "    im_list = []\n",
    "    gt_list = []\n",
    "    disp_list = []\n",
    "    keep_list = []\n",
    "    update_list = []\n",
    "    nolabel_list = []\n",
    "    \n",
    "    for i in range(0,len(disp_list_f)):\n",
    "        \n",
    "        cur_im = cv2.imread(im_left_list_f[i])\n",
    "        cur_nolabel = cv2.imread(nolabel_list_f[i])\n",
    "        \n",
    "        #normalize\n",
    "        #not quite sure if that was really the reason...\n",
    "        #cur_im = (cur_im - np.min(cur_im)) / (np.max(cur_im) - np.min(cur_im))\n",
    "        \n",
    "        cur_disp, _ = readPFM(disp_list_f[i])\n",
    "        cur_gt, _ = readPFM(gt_list_f[i])\n",
    "        \n",
    "        cur_disp[np.isnan(cur_disp)] = 0\n",
    "        cur_disp[np.isinf(cur_disp)] = 0\n",
    "\n",
    "        cur_gt[np.isnan(cur_gt)] = 0\n",
    "        cur_gt[np.isinf(cur_gt)] = 0\n",
    "        \n",
    "        cur_keep = cv2.imread(keepMask_list_f[i])\n",
    "        cur_upd = cv2.imread(updateMask_list_f[i])\n",
    "        \n",
    "        cur_keep = np.mean(cur_keep, axis=2)\n",
    "        cur_upd = np.mean(cur_upd, axis=2)\n",
    "        cur_nolabel = np.mean(cur_nolabel, axis=2)\n",
    "\n",
    "        cur_keep = cur_keep / 255\n",
    "        cur_upd = cur_upd / 255            \n",
    "        cur_nolabel = cur_nolabel / 255     \n",
    "        \n",
    "        im_list.append(cur_im)\n",
    "        gt_list.append(cur_gt)\n",
    "        disp_list.append(cur_disp)\n",
    "        keep_list.append(cur_keep)\n",
    "        update_list.append(cur_upd)\n",
    "        nolabel_list.append(cur_nolabel)\n",
    "        \n",
    "\n",
    "    return disp_list, gt_list, keep_list, update_list, im_list, nolabel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(dataset == 'MB' or dataset == 'MB2021'):\n",
    "    disp_list, gt_list, im_list = loadMB()\n",
    "\n",
    "if(dataset == 'MBEval'):\n",
    "    disp_list, gt_list, keep_list, upd_list, im_list = loadMBEval()\n",
    "\n",
    "if(dataset == 'Kitti2012'):\n",
    "    disp_list, gt_list, keep_list, upd_list, im_list = loadKitti2012()\n",
    "\n",
    "if(dataset == 'Kitti2012Test'):\n",
    "    disp_list, keep_list, upd_list, im_list = loadKitti2012Test()\n",
    "\n",
    "if(dataset == 'Kitti2015'):\n",
    "    disp_list, gt_list, keep_list, upd_list, im_list = loadKitti2015()\n",
    "\n",
    "if(dataset == 'Kitti2015Test'):\n",
    "    disp_list, keep_list, upd_list, im_list = loadKitti2015Test()\n",
    "\n",
    "if(dataset == 'ETH3D'):\n",
    "    disp_list, gt_list, keep_list, upd_list, im_list, nolabel_list = loadETH3D() \n",
    "\n",
    "if(dataset == 'ETH3DTest'):\n",
    "    disp_list, keep_list, upd_list, im_list = loadETH3DTest() \n",
    "\n",
    "if(dataset == 'Sintel'):\n",
    "    disp_list, gt_list, keep_list, upd_list, im_list = loadSintel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InitSingleNew(disp, name,out_folder, gt_f):\n",
    "\n",
    "    avg_two_pe = 0.0    \n",
    "    s_range = 290\n",
    "    chan = 80\n",
    "\n",
    "    disp_shifted_list_right = []\n",
    "    disp_shifted_list_left = []\n",
    "    for i in range(0,int(s_range)):\n",
    "        img_shift_right = shift_image(disp, -i, 0)\n",
    "        disp_shifted_list_right.append(img_shift_right)\n",
    "\n",
    "        img_shift_left = shift_image(disp, i, 0)\n",
    "        disp_shifted_list_left.append(img_shift_left)\n",
    "\n",
    "\n",
    "    disp_shifted_list_right = np.array(disp_shifted_list_right)\n",
    "    disp_shifted_list_left = np.array(disp_shifted_list_left)\n",
    "\n",
    "    c,h,w = disp_shifted_list_right.shape\n",
    "    pred = np.zeros((h,w))\n",
    "\n",
    "    for h_ in range(h):\n",
    "        for w_ in range(0,250):\n",
    "            s_cur = disp_shifted_list_right[:,h_,w_]\n",
    "            s_cur = s_cur[s_cur != 0]\n",
    "            \n",
    "            #not enough non-zero elements in list\n",
    "            if(len(s_cur) < chan):\n",
    "                #copy over other values\n",
    "                val2fill = chan - len(s_cur)\n",
    "                s_cur = np.resize(s_cur,chan)\n",
    "                s_cur[val2fill:chan] = s_cur[0]\n",
    "\n",
    "            #first non-zero element!\n",
    "            pred[h_,w_] = s_cur[0]    \n",
    "\n",
    "    for h_ in range(h):\n",
    "        for w_ in range(250,w):\n",
    "            s_cur = disp_shifted_list_left[:,h_,w_]\n",
    "            s_cur = s_cur[s_cur != 0]\n",
    "\n",
    "            #not enough non-zero elements in list\n",
    "            if(len(s_cur) < chan):\n",
    "                #copy over other values\n",
    "                val2fill = chan - len(s_cur)\n",
    "                s_cur = np.resize(s_cur,chan)\n",
    "                s_cur[val2fill:chan] = s_cur[0]\n",
    "\n",
    "            #first non-zero element!\n",
    "            pred[h_,w_] = s_cur[0]\n",
    "\n",
    "    upd = np.zeros((h,w))\n",
    "    upd[np.where(disp == 0)] = 1\n",
    "\n",
    "    keep = np.zeros((h,w))\n",
    "    keep[np.where(upd == 0)] = 1\n",
    "\n",
    "    keep_t = disp * keep\n",
    "    upd_t = upd\n",
    "\n",
    "    final_outp = keep_t + upd_t\n",
    "    final_outp = final_outp.astype(np.float32)\n",
    "    final_outp = np.squeeze(final_outp)\n",
    "\n",
    "    writePFM(out_folder + name + '_init.pfm', final_outp)\n",
    "\n",
    "    if(gt_f is not None):\n",
    "        gt, _ = readPFM(gt_f)\n",
    "        \n",
    "        gt[np.isinf(gt)] = 0\n",
    "        gt[np.isnan(gt)] = 0\n",
    "        \n",
    "        diff = np.abs(final_outp - gt)\n",
    "        \n",
    "        new_upd_mask = np.zeros((h,w))\n",
    "        \n",
    "        new_upd_mask[np.where(diff > 2.0)] = 1\n",
    "\n",
    "\n",
    "        #also create invalid gt mask? => data needs to be upd but if there is no gt? \n",
    "        new_upd_mask = new_upd_mask * 255\n",
    "\n",
    "        new_keep_mask = np.zeros((h,w))\n",
    "        new_keep_mask[np.where(new_upd_mask == 0)] = 1\n",
    "        new_keep_mask =  new_keep_mask * 255\n",
    "\n",
    "        cv2.imwrite(out_folder + 'upd_mask_init' + name + '.png', new_upd_mask.astype(np.uint8))\n",
    "        cv2.imwrite(out_folder + 'keep_mask_init' + name + '.png', new_keep_mask.astype(np.uint8))\n",
    "\n",
    "        \n",
    "        \n",
    "        five_pe, four_pe, three_pe, two_pe, one_pe, pf_pe = calcEPE(final_outp, gt.astype(np.float32))     \n",
    "        avg_two_pe = avg_two_pe + two_pe\n",
    "        print(\"{} 2-PE after Init: {}\".format(name, two_pe))\n",
    "        return final_outp, new_upd_mask, new_keep_mask\n",
    "\n",
    "    return final_outp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createShiftPytZero(image):\n",
    "    \n",
    "    counter = np.ones((image.shape[0],image.shape[1])) * chan\n",
    "    counterT = Variable(Tensor(counter))\n",
    "    \n",
    "    shift_arr = np.zeros((chan,image.shape[0],image.shape[1]))\n",
    "    shift_arrT = Variable(Tensor(shift_arr))\n",
    "\n",
    "    i = 0\n",
    "    while(torch.sum(counterT) > 0):\n",
    "\n",
    "        if(i == image.shape[1]):\n",
    "            i = 0\n",
    "            \n",
    "        if(i % 2 == 0):                \n",
    "            ex_s = torch.roll(image,-i)\n",
    "            #ex_s = torch.roll(image,i)\n",
    "            #set left side of tensor to zero to mimick old createshift\n",
    "            ex_s[:,chan-i:chan] = 0\n",
    "            \n",
    "        if(i % 2 == 1):\n",
    "            ex_s = torch.roll(image,i)\n",
    "            #ex_s = torch.roll(image,-i)\n",
    "            #set right side of tensor to zero to mimick old createshift\n",
    "            ex_s[:,0:i] = 0\n",
    "            \n",
    "        \n",
    "        idc = torch.nonzero(ex_s, as_tuple = True)\n",
    "\n",
    "        counterT[idc[0],idc[1]] += -1\n",
    "        \n",
    "        max_loop = torch.min(counterT).cpu().data.numpy().astype(np.int)\n",
    "\n",
    "        #it overwrites lines that already have values with 0's!!!\n",
    "        for d in range(max_loop,chan):\n",
    "            \n",
    "            idx_cur = torch.where(counterT == d)\n",
    "            slice_tensor = torch.zeros(ex_s.shape[0], ex_s.shape[1]).cuda()\n",
    "            slice_tensor[idx_cur[0].long(),idx_cur[1].long()] = ex_s[idx_cur[0].long(),idx_cur[1].long()]\n",
    "            \n",
    "            idc_slice = torch.nonzero(slice_tensor, as_tuple = True)\n",
    "            shift_arrT[d, idc_slice[0].long(),idc_slice[1].long()] = ex_s[idc_slice[0].long(),idc_slice[1].long()]\n",
    "            \n",
    "        counterT[counterT < 0] = 0\n",
    "        i = i + 1\n",
    "                    \n",
    "    return shift_arrT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_image(X, dx, dy):\n",
    "    X = np.roll(X, dy, axis=0)\n",
    "    X = np.roll(X, dx, axis=1)\n",
    "    if dy>0:\n",
    "        X[:dy, :] = 0\n",
    "    elif dy<0:\n",
    "        X[dy:, :] = 0\n",
    "    if dx>0:\n",
    "        X[:, :dx] = 0\n",
    "    elif dx<0:\n",
    "        X[:, dx:] = 0\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20020,
     "status": "ok",
     "timestamp": 1615907243026,
     "user": {
      "displayName": "Dominik Hirner",
      "photoUrl": "",
      "userId": "16020349886697963223"
     },
     "user_tz": -60
    },
    "id": "gFOTp1UTchKV"
   },
   "outputs": [],
   "source": [
    "#problem if upd_count == 0??\n",
    "def getClass():\n",
    "    \n",
    "    keep_list = []\n",
    "    upd_list = []\n",
    "    disp_list = []\n",
    "    gt_list = []\n",
    "    nolabel_list = []\n",
    "    \n",
    "    for i in range(0,len(disp_list_f)): \n",
    "\n",
    "        \n",
    "        cur_disp, _ = readPFM(disp_list_f[i])\n",
    "        cur_gt, _ = readPFM(gt_list_f[i])\n",
    "        \n",
    "        cur_disp[np.isnan(cur_disp)] = 0\n",
    "        cur_disp[np.isinf(cur_disp)] = 0\n",
    "\n",
    "        cur_gt[np.isnan(cur_gt)] = 0\n",
    "        cur_gt[np.isinf(cur_gt)] = 0\n",
    "        \n",
    "        disp_list.append(cur_disp)\n",
    "        gt_list.append(cur_gt)     \n",
    "        \n",
    "        h,w = cur_disp.shape\n",
    "\n",
    "        cur_upd = np.zeros((h,w))\n",
    "        cur_upd[np.where(cur_disp == 0)] = 1\n",
    "            \n",
    "        cur_keep = np.zeros((h,w))\n",
    "        cur_keep[np.where(cur_upd == 0)] = 1\n",
    "\n",
    "        \n",
    "        keep_list.append(cur_keep)\n",
    "        upd_list.append(cur_upd)    \n",
    "    \n",
    "    total_px_to_upd = 0\n",
    "    for s in range(0,len(disp_list_f)): \n",
    "        \n",
    "        #gets number of 0 and 1 pixels! need 1 pixels (to update)\n",
    "        upd_class,upd_counts = np.unique(upd_list[s], return_counts = True)    \n",
    "        #if upd_counts is not empty\n",
    "        if(len(upd_counts) == 2):\n",
    "            total_px_to_upd = total_px_to_upd + upd_counts[1]\n",
    "    \n",
    "    batch_gt = np.zeros((total_px_to_upd,1))\n",
    "\n",
    "    #count for batch_gt array!\n",
    "    el = 0\n",
    "    nol_count = 0\n",
    "    for c in range(0,len(disp_list_f)):\n",
    "        \n",
    "        print('------------------')\n",
    "        print(disp_list_f[c])\n",
    "        print(gt_list_f[c])\n",
    "        disp = disp_list[c]    \n",
    "        gt = gt_list[c]\n",
    "\n",
    "        keep = keep_list[c]\n",
    "        \n",
    "        disp = disp.copy()\n",
    "        dispT = Variable(Tensor(disp))\n",
    "        \n",
    "        nolabels = np.zeros((disp.shape[0], disp.shape[1]))\n",
    "        \n",
    "        cur_disp_shifted = createShiftPytZero(dispT)\n",
    "        h,w = gt.shape\n",
    "        \n",
    "        #only way to increase performance is to do this for the whole image at once, not per pixel!\n",
    "        #i am sure it is possible but...\n",
    "        for h_ in range(h):\n",
    "            for w_ in range(w):\n",
    "                \n",
    "                if(keep[h_,w_] == 0):\n",
    "                    d_arr = torch.squeeze(cur_disp_shifted[:,h_,w_])\n",
    "                    cur_gt = gt[h_,w_]\n",
    "                    cur_gt = int(np.round(cur_gt))\n",
    "\n",
    "                    gt_label = findGTInDispArrSingle(d_arr, cur_gt, 0)  \n",
    "                    if(gt_label == -1):\n",
    "                        gt_label = findGTInDispArrSingle(d_arr, cur_gt, 1)\n",
    "                        if(gt_label == -1):\n",
    "                            gt_label = findGTInDispArrSingle(d_arr, cur_gt, -1)                        \n",
    "                            if(gt_label == -1):\n",
    "                                gt_label = findGTInDispArrSingle(d_arr, cur_gt, 2)\n",
    "                                if(gt_label == -1):\n",
    "                                    gt_label = findGTInDispArrSingle(d_arr, cur_gt, -2)                        \n",
    "\n",
    "                    #maybe this is the reason! Maybe there are so many\n",
    "                    #zeros because it does not find the labels?\n",
    "                    #test here with -1!\n",
    "                    if(int(gt[h_,w_]) > 0):\n",
    "                        if(gt_label > -1):\n",
    "                            batch_gt[el,0] = int(gt_label)\n",
    "                            el = el + 1\n",
    "                        else:\n",
    "                            nolabels[h_,w_] = 1\n",
    "                            nol_count = nol_count + 1\n",
    "                            \n",
    "        \n",
    "        folder = gt_list_f[c].replace(gt_list_f[c].split('/')[-1],'')\n",
    "        print(folder)\n",
    "                    \n",
    "        name = gt_list_f[c].split('/')[-1].split('.')[0]\n",
    "        print(folder + name + 'no_labels.png')\n",
    "            \n",
    "        cv2.imwrite(folder + name + 'no_labels.png', nolabels * 255)                 \n",
    "        #cv2.imwrite(folder + name + '.png', nolabels * 255)                 \n",
    "        \n",
    "        nolabel_list.append(nolabels)\n",
    "        print('------------------')\n",
    "    \n",
    "    print(\"nolabel count: {}\".format(nol_count))\n",
    "    del cur_disp_shifted\n",
    "    del disp\n",
    "    del gt\n",
    "    \n",
    "    return batch_gt, nolabel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassWeights():\n",
    "    \n",
    "    #should be vec with all classes over all disparities!!\n",
    "    gtlabels2count,nolabel_list = getClass()\n",
    "    gt_classes, gt_counts = np.unique(gtlabels2count.astype(np.uint8), return_counts = True)\n",
    "    \n",
    "    #TODO: Remove pixels with invalid gt from dataset!!! (probably best to include that in keep, update)\n",
    "    #TODO: RE-VISIT THIS! Does it work?\n",
    "    if(len(gt_classes) < (chan)):\n",
    "        for w_ in range(0,chan):\n",
    "            if(w_ not in gt_classes):\n",
    "                gt_counts = np.insert(gt_counts,w_ , 100000)    \n",
    "    norm_w = []\n",
    "    for w_ in range(0,chan):\n",
    "        cur_w = 1 / gt_counts[w_]\n",
    "        norm_w.append(cur_w)\n",
    "    \n",
    "    return norm_w, nolabel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20015,
     "status": "ok",
     "timestamp": 1615907243028,
     "user": {
      "displayName": "Dominik Hirner",
      "photoUrl": "",
      "userId": "16020349886697963223"
     },
     "user_tz": -60
    },
    "id": "09fELQzAchKW",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#write weights\n",
    "if(train):\n",
    "    \n",
    "    \n",
    "    norm_w,nolabel_list = getClassWeights()\n",
    "    with open('mb2021.txt', 'w') as f:\n",
    "        for item in norm_w:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "    \n",
    "    #load weights!\n",
    "    #norm_w=[]\n",
    "    #with open('kitti2015c10.txt', \"r\") as file1:\n",
    "    #    for line in file1.readlines():\n",
    "    #        norm_w.append(float(line))\n",
    "#\n",
    "    ## Important: Convert Weights To Float Tensor\n",
    "    class_weights = torch.FloatTensor(norm_w).cuda()\n",
    "    \n",
    "    #loss_func = nn.CrossEntropyLoss(reduction='none')\n",
    "    #loss_func = nn.MSELoss()\n",
    "    loss_func = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "else:\n",
    "    loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestHolo(out_folder,nr_iter, save):    \n",
    "    \n",
    "    \n",
    "    for i in range(len(disp_list_st1)):\n",
    "        \n",
    "        \n",
    "        t = time.time()\n",
    "        disp, _ = readPFM(disp_list_st1[i])\n",
    "        \n",
    "        disp[np.isnan(disp)] = -1000\n",
    "        disp[np.isinf(disp)] = -1000\n",
    "        \n",
    "        \n",
    "        keep = np.mean(cv2.imread(keep_mask_st1[i]), axis = 2) / 255\n",
    "        upd = np.mean(cv2.imread(upd_mask_st1[i]), axis = 2) / 255\n",
    "        \n",
    "        im = cv2.imread(im_left_list[i])\n",
    "        \n",
    "        h,w,c = im.shape\n",
    "        im = np.reshape(im, (c,h, w))\n",
    "        im = im[np.newaxis,...]        \n",
    "        imT = Variable(Tensor(im.astype(np.uint8)))\n",
    "\n",
    "        upd = np.zeros((disp.shape[0],disp.shape[1]))\n",
    "        upd[np.where(disp == -1000)] = 1\n",
    "\n",
    "        keep = np.zeros((disp.shape[0],disp.shape[1]))\n",
    "        keep[np.where(upd == 0)] = 1\n",
    "\n",
    "        keep_t = disp * keep\n",
    "        \n",
    "        updT = Variable(Tensor(upd.astype(np.float32)))\n",
    "        keepT_t = Variable(Tensor(keep_t.astype(np.float32)))\n",
    "        \n",
    "        #fuck!! uint8 does not support neg. values!!!!\n",
    "        #have to think about a way around this!!!\n",
    "        dispT = Variable(Tensor(disp.astype(np.float32)))\n",
    "        \n",
    "        for d in range(0,nr_iter):\n",
    "\n",
    "            #cur_disp_shiftedL = createShiftPytLeft(dispT)\n",
    "            #cur_disp_shiftedR = createShiftPytRight(dispT)\n",
    "\n",
    "            #cur_disp_shifted = torch.cat((cur_disp_shiftedL,cur_disp_shiftedR),axis = 0)\n",
    "            #dispShift = torch.cat((cur_disp_shiftedL,cur_disp_shiftedR),axis = 0)        \n",
    "            #print(dispT)\n",
    "            dispShift = createShiftPytZero(dispT)\n",
    "            #print(dispShift)\n",
    "            dispShift = dispShift.unsqueeze(0)\n",
    "            \n",
    "            OutT = updInc(dispShift,imT) \n",
    "            OutT = torch.squeeze(OutT)\n",
    "\n",
    "            bs,c,x,y = dispShift.shape\n",
    "\n",
    "            idc_for_updt = torch.argmax(OutT, axis=0).unsqueeze(0)  \n",
    "            pred = torch.gather(np.squeeze(dispShift), 0, idc_for_updt).squeeze()\n",
    "            \n",
    "            updT_t = pred * updT\n",
    "            \n",
    "            final_outp = keepT_t + updT_t\n",
    "            \n",
    "            #writePFM(out_folder + '%03i_%03i.pfm' %(d,i), updT_t.cpu().data.numpy().astype(np.float32))\n",
    "\n",
    "            dispT = final_outp\n",
    "            \n",
    "            elapsed = time.time() - t\n",
    "            print (\"Time: {}\".format(elapsed))\n",
    "            \n",
    "            del OutT\n",
    "            del idc_for_updt\n",
    "            del dispShift\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        disp_arr = dispT.cpu().data.numpy().astype(np.float32)\n",
    "        \n",
    "        disp_arr = cv2.medianBlur(disp_arr,5) \n",
    "        \n",
    "        name = disp_list_st1[i].split('/')[-1]\n",
    "        \n",
    "        f= open(out_folder + name +'.txt',\"w+\")   \n",
    "        f.write(\"runtime \" + str(elapsed))\n",
    "     \n",
    "        if(save == True):\n",
    "            writePFM(out_folder + name +'.pfm' , disp_arr)\n",
    "            #writePFM(out_folder + name +'.pfm' , pred.cpu().data.numpy().astype(np.float32))\n",
    "            \n",
    "            \n",
    "            \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all general data \n",
    "def TestGen(out_folder,nr_iter, save):    \n",
    "    \n",
    "    for i in range(len(disp_list_st1)):\n",
    "        \n",
    "        t = time.time()\n",
    "        \n",
    "        \n",
    "        disp, _ = readPFM(disp_list_st1[i])\n",
    "        \n",
    "        disp[np.isnan(disp)] = 0\n",
    "        disp[np.isinf(disp)] = 0\n",
    "        \n",
    "        \n",
    "        keep = np.mean(cv2.imread(keep_mask_st1[i]), axis = 2) / 255\n",
    "        upd = np.mean(cv2.imread(upd_mask_st1[i]), axis = 2) / 255\n",
    "        \n",
    "        im = cv2.imread(im_left_list[i])\n",
    "        \n",
    "        h,w,c = im.shape\n",
    "        im = np.reshape(im, (c,h, w))\n",
    "        im = im[np.newaxis,...]        \n",
    "        imT = Variable(Tensor(im.astype(np.uint8)))\n",
    "\n",
    "        upd = np.zeros((disp.shape[0],disp.shape[1]))\n",
    "        upd[np.where(disp == 0)] = 1\n",
    "\n",
    "        keep = np.zeros((disp.shape[0],disp.shape[1]))\n",
    "        keep[np.where(upd == 0)] = 1\n",
    "\n",
    "        keep_t = disp * keep\n",
    "        \n",
    "        updT = Variable(Tensor(upd.astype(np.float32)))\n",
    "        keepT_t = Variable(Tensor(keep_t.astype(np.float32)))\n",
    "        #fuck!! uint8 does not support neg. values!!!!\n",
    "        #have to think about a way around this!!!\n",
    "        \n",
    "        dispT = Variable(Tensor(disp.astype(np.uint8)))\n",
    "        \n",
    "        for d in range(0,nr_iter):\n",
    "\n",
    "            dispShift = createShiftPytZero(dispT)\n",
    "            dispShift = dispShift.unsqueeze(0)\n",
    "            \n",
    "            OutT = updInc(dispShift,imT) \n",
    "            OutT = torch.squeeze(OutT)\n",
    "\n",
    "            bs,c,x,y = dispShift.shape\n",
    "\n",
    "            idc_for_updt = torch.argmax(OutT, axis=0).unsqueeze(0)  \n",
    "            pred = torch.gather(np.squeeze(dispShift), 0, idc_for_updt).squeeze()\n",
    "            \n",
    "            updT_t = pred * updT\n",
    "            \n",
    "            final_outp = keepT_t + updT_t\n",
    "            \n",
    "            #writePFM(out_folder + '%03i_%03i.pfm' %(d,i), updT_t.cpu().data.numpy().astype(np.float32))\n",
    "\n",
    "            dispT = final_outp\n",
    "            \n",
    "            elapsed = time.time() - t\n",
    "            print (\"Time: {}\".format(elapsed))\n",
    "            \n",
    "            del OutT\n",
    "            del idc_for_updt\n",
    "            del dispShift\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        disp_arr = dispT.cpu().data.numpy().astype(np.float32)\n",
    "        \n",
    "        disp_arr = cv2.medianBlur(disp_arr,5) \n",
    "        \n",
    "        name = disp_list_st1[i].split('/')[-1]\n",
    "        \n",
    "        f= open(out_folder + name +'.txt',\"w+\")   \n",
    "        f.write(\"runtime \" + str(elapsed))\n",
    "     \n",
    "        if(save == True):\n",
    "            writePFM(out_folder + name +'.pfm' , disp_arr)       \n",
    "            \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how are there float values here????\n",
    "def TestETHTestRecurrent(out_folder,nr_iter, save):\n",
    "    \n",
    "    #n_list = glob.glob('/media/HDD/TrainingsData/ETH3D/two_view_test/*')\n",
    "    #n_list = sorted(n_list)\n",
    "    \n",
    "    n_list = disp_list_st1\n",
    "    \n",
    "    for i in range(len(disp_list_f)):\n",
    "        \n",
    "        t = time.time()\n",
    "        \n",
    "        disp  = disp_list[i]\n",
    "        keep = keep_list[i]\n",
    "        upd = upd_list[i]\n",
    "        im = im_list[i]\n",
    "        \n",
    "        print(disp.shape)\n",
    "        print(im.shape)\n",
    "        \n",
    "        h,w,c = im.shape\n",
    "        im = np.reshape(im, (c,h, w))\n",
    "        im = im[np.newaxis,...]        \n",
    "        imT = Variable(Tensor(im.astype(np.uint8)))\n",
    "\n",
    "        upd = np.zeros((disp.shape[0],disp.shape[1]))\n",
    "        upd[np.where(disp == 0)] = 1\n",
    "\n",
    "        keep = np.zeros((disp.shape[0],disp.shape[1]))\n",
    "        keep[np.where(upd == 0)] = 1\n",
    "\n",
    "        keep_t = disp * keep\n",
    "        \n",
    "        updT = Variable(Tensor(upd.astype(np.float32)))\n",
    "        keepT_t = Variable(Tensor(keep_t.astype(np.float32)))\n",
    "        dispT = Variable(Tensor(disp.astype(np.uint8)))\n",
    "        \n",
    "        for d in range(0,nr_iter):\n",
    "\n",
    "            #cur_disp_shiftedL = createShiftPytLeft(dispT)\n",
    "            #cur_disp_shiftedR = createShiftPytRight(dispT)\n",
    "\n",
    "            #cur_disp_shifted = torch.cat((cur_disp_shiftedL,cur_disp_shiftedR),axis = 0)\n",
    "            #dispShift = torch.cat((cur_disp_shiftedL,cur_disp_shiftedR),axis = 0)        \n",
    "            dispShift = createShiftPytZero(dispT)\n",
    "            dispShift = dispShift.unsqueeze(0)\n",
    "            \n",
    "            OutT = updInc(dispShift,imT) \n",
    "            OutT = torch.squeeze(OutT)\n",
    "\n",
    "            bs,c,x,y = dispShift.shape\n",
    "\n",
    "            idc_for_updt = torch.argmax(OutT, axis=0).unsqueeze(0)  \n",
    "            pred = torch.gather(np.squeeze(dispShift), 0, idc_for_updt).squeeze()\n",
    "            \n",
    "            updT_t = pred * updT\n",
    "            \n",
    "            final_outp = keepT_t + updT_t\n",
    "            \n",
    "            #writePFM(out_folder + '%03i_%03i.pfm' %(d,i), updT_t.cpu().data.numpy().astype(np.float32))\n",
    "\n",
    "            dispT = final_outp\n",
    "            \n",
    "            elapsed = time.time() - t\n",
    "            #print (\"Time: {}\".format(elapsed))\n",
    "            \n",
    "            del OutT\n",
    "            del idc_for_updt\n",
    "            del dispShift\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        disp_arr = dispT.cpu().data.numpy().astype(np.float32)\n",
    "        disp_arr = cv2.medianBlur(disp_arr,5)        \n",
    "        name = n_list[i].split('/')[-1]\n",
    "        print(name)\n",
    "        f= open(out_folder + name +'.txt',\"w+\")   \n",
    "        f.write(\"runtime \" + str(elapsed))\n",
    "     \n",
    "        if(save == True):\n",
    "            writePFM(out_folder + name +'.pfm' , disp_arr)\n",
    "            \n",
    "            \n",
    "            \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how are there float values here????\n",
    "def TestMBRecurrent(out_folder,nr_iter, save):\n",
    "    \n",
    "    n_list = disp_list_f\n",
    "    avg_five_pe = 0.0\n",
    "    avg_four_pe = 0.0 \n",
    "    avg_three_pe = 0.0 \n",
    "    avg_two_pe = 0.0\n",
    "    avg_one_pe = 0.0\n",
    "    avg_pf_pe = 0.0\n",
    "    nr_samples = len(disp_list_f)\n",
    "    \n",
    "    for i in range(len(disp_list_f)): \n",
    "        \n",
    "        t = time.time()\n",
    "        \n",
    "        disp  = disp_list[i]\n",
    "        gt = gt_list[i]\n",
    "        im = im_list[i]\n",
    "\n",
    "        h,w,c = im.shape\n",
    "        im = np.reshape(im, (c,h, w))\n",
    "        im = im[np.newaxis,...]        \n",
    "        imT = Variable(Tensor(im.astype(np.uint8)))\n",
    "\n",
    "        upd = np.zeros((disp.shape[0],disp.shape[1]))\n",
    "        upd[np.where(disp == 0)] = 1\n",
    "\n",
    "        keep = np.zeros((disp.shape[0],disp.shape[1]))\n",
    "        keep[np.where(upd == 0)] = 1\n",
    "\n",
    "        keep_t = disp * keep\n",
    "        \n",
    "        updT = Variable(Tensor(upd.astype(np.float32)))\n",
    "        keepT_t = Variable(Tensor(keep_t.astype(np.float32)))\n",
    "        dispT = Variable(Tensor(disp.astype(np.uint8)))\n",
    "        \n",
    "        for d in range(0,nr_iter):\n",
    "\n",
    "            dispShift = createShiftPytZero(dispT)\n",
    "            dispShift = dispShift.unsqueeze(0)\n",
    "            \n",
    "            OutT = updInc(dispShift,imT) \n",
    "            OutT = torch.squeeze(OutT)\n",
    "\n",
    "            bs,c,x,y = dispShift.shape\n",
    "\n",
    "            idc_for_updt = torch.argmax(OutT, axis=0).unsqueeze(0)  \n",
    "            pred = torch.gather(np.squeeze(dispShift), 0, idc_for_updt).squeeze()\n",
    "            \n",
    "            updT_t = pred * updT\n",
    "            \n",
    "            final_outp = keepT_t + updT_t\n",
    "            dispT = final_outp\n",
    "            \n",
    "            elapsed = time.time() - t\n",
    "            print (\"Time: {}\".format(elapsed))\n",
    "            \n",
    "            del OutT\n",
    "            del idc_for_updt\n",
    "            del dispShift\n",
    "            torch.cuda.empty_cache()  \n",
    "            \n",
    "            \n",
    "        disp_arr = dispT.cpu().data.numpy().astype(np.float32)\n",
    "        disp_arr = cv2.medianBlur(disp_arr,5)\n",
    "\n",
    "        five_pe, four_pe, three_pe, two_pe, one_pe, pf_pe = calcEPE(disp_arr, gt.astype(np.float32))\n",
    "        \n",
    "        print(\"2-PE: {}\".format(two_pe))\n",
    "        \n",
    "        avg_five_pe = avg_five_pe + five_pe\n",
    "        avg_four_pe = avg_four_pe +  four_pe\n",
    "        avg_three_pe = avg_three_pe + three_pe\n",
    "        avg_two_pe = avg_two_pe + two_pe\n",
    "        avg_one_pe = avg_one_pe + one_pe\n",
    "        avg_pf_pe = avg_pf_pe + pf_pe        \n",
    "        \n",
    "        name = n_list[i].split('/')[-1].replace('_s.pfm', '')\n",
    "        if(save == True):\n",
    "            writePFM(out_folder + name +'.pfm' , disp_arr)\n",
    "        \n",
    "        f= open(out_folder + name +'.txt',\"w+\")   \n",
    "        f.write(\"runtime \" + str(elapsed))\n",
    "            \n",
    "    avg_four_pe = avg_four_pe / nr_samples\n",
    "    avg_two_pe = avg_two_pe / nr_samples\n",
    "    avg_one_pe = avg_one_pe / nr_samples\n",
    "    avg_pf_pe = avg_pf_pe / nr_samples\n",
    "    \n",
    "    print(\"4-PE: {}\".format(avg_four_pe))\n",
    "    print(\"2-PE: {}\".format(avg_two_pe))\n",
    "    print(\"1-PE: {}\".format(avg_one_pe))\n",
    "    print(\"0.5-PE: {}\".format(avg_pf_pe))\n",
    "    return avg_two_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how are there float values here????\n",
    "#somehow wrong!\n",
    "def TestMB(out_folder,nr_iter, save):\n",
    "    \n",
    "    avg_two_pe = 0.0\n",
    "    \n",
    "    for i in range(len(disp_list_f)): #len(disp_list_f)\n",
    "\n",
    "        disp  = disp_list[i]\n",
    "        gt = gt_list[i]\n",
    "        im = im_list[i]\n",
    "        \n",
    "        h,w = disp.shape\n",
    "        \n",
    "        upd = np.zeros((h,w))\n",
    "        upd[np.where(disp == 0)] = 1\n",
    "            \n",
    "        keep = np.zeros((h,w))\n",
    "        keep[np.where(upd == 0)] = 1\n",
    "        \n",
    "\n",
    "        h,w,c = im.shape\n",
    "        im = np.reshape(im, (c,h, w))\n",
    "        im = im[np.newaxis,...]\n",
    "        imT = Variable(Tensor(im.astype(np.uint8)))\n",
    "\n",
    "        upd = np.zeros((disp.shape[0],disp.shape[1]))\n",
    "        upd[np.where(disp == 0)] = 1\n",
    "\n",
    "        keep = np.zeros((disp.shape[0],disp.shape[1]))\n",
    "        keep[np.where(upd == 0)] = 1\n",
    "\n",
    "        keep_t = disp * keep\n",
    "        \n",
    "        updT = Variable(Tensor(upd.astype(np.float32)))\n",
    "        keepT_t = Variable(Tensor(keep_t.astype(np.float32)))\n",
    "        dispT = Variable(Tensor(disp.astype(np.uint8)))\n",
    "        \n",
    "        #cur_disp_shiftedL = createShiftPytLeft(dispT)\n",
    "        #cur_disp_shiftedR = createShiftPytRight(dispT)\n",
    "\n",
    "        #cur_disp_shifted = torch.cat((cur_disp_shiftedL,cur_disp_shiftedR),axis = 0)\n",
    "        dispShift = createShiftPytZero(dispT)\n",
    "        #dispShift = torch.cat((cur_disp_shiftedL,cur_disp_shiftedR),axis = 0)        \n",
    "        #dispShift = Variable(Tensor(createShiftLR(disp)))\n",
    "        #unfortunately there are still many 0s in this...\n",
    "        #print(dispShift)\n",
    "        \n",
    "        dispShift = dispShift.unsqueeze(0)\n",
    "        \n",
    "        OutT = updInc(dispShift,imT) \n",
    "        OutT = torch.squeeze(OutT)\n",
    "        bs,c,x,y = dispShift.shape\n",
    "\n",
    "        idc_for_updt = torch.argmax(OutT, axis=0).unsqueeze(0)  \n",
    "        pred = torch.gather(np.squeeze(dispShift), 0, idc_for_updt).squeeze()\n",
    "\n",
    "        updT_t = pred * updT\n",
    "\n",
    "        final_outp = keepT_t + updT_t\n",
    "\n",
    "        #writePFM(out_folder + '%03i_%03i.pfm' %(d,i), updT_t.cpu().data.numpy().astype(np.float32))\n",
    "\n",
    "        dispT = final_outp\n",
    "            \n",
    "\n",
    "        five_pe, four_pe, three_pe, two_pe, one_pe, pf_pe = calcEPE(dispT.cpu().data.numpy().astype(np.float32), gt.astype(np.float32))\n",
    "        avg_two_pe = two_pe + avg_two_pe   \n",
    "        \n",
    "        if(save == True):\n",
    "            writePFM(out_folder + '_%03i.pfm' %i, final_outp.cpu().data.numpy().astype(np.float32))\n",
    "            \n",
    "        del dispT\n",
    "        del idc_for_updt\n",
    "        del updT_t\n",
    "        del OutT\n",
    "        del dispShift\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        \n",
    "    avg_two_pe = avg_two_pe / len(disp_list_f)\n",
    "    return avg_two_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBatch(nr_ex, disp_list):\n",
    "    \n",
    "    batch_x = Variable(Tensor(np.zeros((nr_ex,chan,patch_size,patch_size))))\n",
    "    \n",
    "    batch_gt = np.zeros((nr_ex,patch_size,patch_size))\n",
    "    batch_im = np.zeros((nr_ex,3,patch_size,patch_size))\n",
    "    \n",
    "    ridx = np.random.randint(0,len(disp_list_f),1)\n",
    "        \n",
    "    disp = disp_list[ridx[0]]    \n",
    "    gt = gt_list[ridx[0]]\n",
    "    \n",
    "    im = im_list[ridx[0]]\n",
    "    h,w,c = im.shape\n",
    "    im = np.reshape(im, (c,h, w))\n",
    "    \n",
    "    h,w = disp.shape\n",
    "    upd = np.zeros((h,w))\n",
    "    upd[np.where(disp == 0)] = 1\n",
    "\n",
    "    keep = np.zeros((h,w))\n",
    "    keep[np.where(upd == 0)] = 1\n",
    "\n",
    "        \n",
    "    nolabel = nolabel_list[ridx[0]]\n",
    "    dispT = Variable(Tensor(disp.astype(np.uint8)))\n",
    "    cur_disp_shifted = createShiftPytZero(dispT)\n",
    "\n",
    "    h,w = gt.shape\n",
    "    r_low = h\n",
    "    r_high = w\n",
    "    \n",
    "    for el in range(nr_ex):\n",
    "        #get random position\n",
    "        c,h,w = cur_disp_shifted.shape\n",
    "        r_h = 0\n",
    "        r_w = 0\n",
    "        d = 0\n",
    "        \n",
    "        r_h = random.sample(range(0,h), 1)\n",
    "        r_w = random.sample(range(0,w),1)\n",
    "        d_arr = torch.squeeze(cur_disp_shifted[:,r_h[0]-ps_h:r_h[0]+(ps_h+1),r_w[0]-ps_h:r_w[0]+(ps_h+1)])\n",
    "        cur_gt = gt[r_h[0]-ps_h:r_h[0]+(ps_h+1),r_w[0]-ps_h:r_w[0]+(ps_h+1)]\n",
    "        cur_gt = cur_gt.astype(np.uint8)\n",
    "        \n",
    "        i = 0\n",
    "        \n",
    "        while(True): \n",
    "            r_h = random.sample(range(0,h), 1)\n",
    "            r_w = random.sample(range(0,w), 1)\n",
    "            i = i + 1\n",
    "            if(r_h[0]-ps_h > 0):\n",
    "              if(r_h[0]+ps_h < h):\n",
    "                if(r_w[0]-ps_h > 0):\n",
    "                  if(r_w[0]+ps_h < w):\n",
    "                    if(int(gt[r_h[0],r_w[0]]) > 0):\n",
    "                        if(keep[r_h[0],r_w[0]] == 0):\n",
    "                            if(nolabel[r_h[0],r_w[0]] == 0):\n",
    "                          \n",
    "                                d_arr = torch.squeeze(cur_disp_shifted[:,r_h[0]-ps_h:r_h[0]+(ps_h+1),r_w[0]-ps_h:r_w[0]+(ps_h+1)])\n",
    "                                cur_gt = gt[r_h[0]-ps_h:r_h[0]+(ps_h+1),r_w[0]-ps_h:r_w[0]+(ps_h+1)]\n",
    "                                cur_gt = cur_gt.astype(np.uint8)\n",
    "                                gt_label = findGTInDispArr(d_arr.cpu().data.numpy().astype(np.float32), cur_gt, 0)\n",
    "                                #print(gt_label)\n",
    "                                break\n",
    "        \n",
    "        cur_disp = cur_disp_shifted[:,r_h[0]-ps_h:r_h[0]+(ps_h+1),r_w[0]-ps_h:r_w[0]+(ps_h+1)]\n",
    "        batch_x[el,:,:,:] = cur_disp       \n",
    "        batch_gt[el,:,:] = gt_label\n",
    "\n",
    "        batch_im[el,:,:,:] = im[:,r_h[0]-ps_h:r_h[0]+(ps_h+1),r_w[0]-ps_h:r_w[0]+(ps_h+1)]\n",
    "        \n",
    "    return batch_x, batch_gt, batch_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#KITTI2012 W\n",
    "#updInc.load_state_dict(torch.load('/media/HDD/ICPR-AblationStudies/fillOld_TrainedFill/Out/Kitti2012/DC/weights/Incons_107200e3.524451'))\n",
    "#MB W\n",
    "#updInc.load_state_dict(torch.load('/media/HDD/ICPR-AblationStudies/fillOld_TrainedFill/Out/weights/Incons_1934000e9.957338'))\n",
    "#KITTI2015 W\n",
    "#updInc.load_state_dict(torch.load('/media/HDD/ICPR-AblationStudies/fillOld_TrainedFill/Out/Kitti2015/DC/weights/Incons_031500e15.517040'))\n",
    "\n",
    "#i = 0\n",
    "#avg_two_pe = TestMB(out_folder,i, True)\n",
    "#print(avg_two_pe)\n",
    "\n",
    "#write here the output of every iteration!\n",
    "#pick best looking!\n",
    "#also from satellite image\n",
    "\n",
    "#TestGen(out_folder,1, True)\n",
    "#TestHolo(out_folder,5, True)\n",
    "\n",
    "#avg_two_pe = TestMBFillIncons(out_folder)\n",
    "#print(avg_two_pe)\n",
    "\n",
    "#TestETHTestRecurrent(out_folder,5, True)\n",
    "\n",
    "\n",
    "#MB2021 W\n",
    "#updInc.load_state_dict(torch.load('/media/HDD/ICPR-AblationStudies/fillOld_TrainedFill/Out/MB2021/weights/Incons_002000e23.797647'))\n",
    "\n",
    "avg_two_pe = TestMBRecurrent(out_folder,2, True)\n",
    "print(avg_two_pe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 116897,
     "status": "error",
     "timestamp": 1615907339919,
     "user": {
      "displayName": "Dominik Hirner",
      "photoUrl": "",
      "userId": "16020349886697963223"
     },
     "user_tz": -60
    },
    "id": "Nag79pv-chKW",
    "outputId": "7e38ab16-19e4-43bd-e7c2-07a345c5695f",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#to beat with MB2021: 23.386614041310064\n",
    "if(train):\n",
    "    optimizer_G = optim.Adam(updInc.parameters(),  lr=0.000006) #0.000006\n",
    "   \n",
    "    best_two_pe = 100\n",
    "\n",
    "    dispShift, gt, im = getBatch(batch_size, disp_list)\n",
    "    \n",
    "    #dispShift, gt, im, keep, upd = getBatchWholeIm(disp_list)\n",
    "\n",
    "    imT = Variable(Tensor(im.astype(np.uint8)))\n",
    "    gtT = Variable(LTensor(gt.astype(np.uint8)))\n",
    "\n",
    "    \n",
    "    for i in range(nr_epochs):\n",
    "        \n",
    "        #reset gradients\n",
    "        optimizer_G.zero_grad()\n",
    "        OutT = updInc(dispShift,imT) \n",
    "                \n",
    "        loss = loss_func(OutT, gtT)\n",
    "        loss = torch.mean(loss)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        save = 1000\n",
    "\n",
    "        if(i % save == 0):            \n",
    "            \n",
    "            print(\"EPOCH: {} CE-loss: {}\".format(i,loss))  \n",
    "            #probably does backprop!\n",
    "            #avg_two_pe = TestMBRecurrent(out_folder,i, False)\n",
    "            avg_two_pe = TestMB(out_folder,1, False)\n",
    "            \n",
    "            print(\"2-PE Depth-Completion: {}\".format(avg_two_pe))\n",
    "\n",
    "            if(avg_two_pe < best_two_pe):\n",
    "                \n",
    "                avg_two_pe = TestMB(out_folder,i, True)\n",
    "                print(colored('------------------', 'green', attrs=['bold']))                         \n",
    "                print(colored('NEW PB network: {}'.format(avg_two_pe), 'green', attrs=['bold']))  \n",
    "                print(colored('------------------', 'green', attrs=['bold']))                         \n",
    "\n",
    "                best_two_pe = avg_two_pe\n",
    "                torch.save(updInc.state_dict(), w_folder + model_name + '_%06i' %(i) + 'e%06f' %(best_two_pe)) \n",
    "\n",
    "            dispShift, gt, im = getBatch(batch_size, disp_list)\n",
    "            \n",
    "            imT = Variable(Tensor(im.astype(np.uint8)))\n",
    "            gtT = Variable(LTensor(gt.astype(np.uint8)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FillNWPyramid30FC.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
