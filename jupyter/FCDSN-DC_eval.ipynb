{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FCDSN-DC evaluation notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) DI Dominik Hirner BSc. \n",
    "Institute for graphics and vision (ICG)\n",
    "University of Technology Graz, Austria\n",
    "E-mail: dominik.hirner@icg.tugraz.at\n",
    "\n",
    "This notebook is the equivalent to the test.py script in the root folder of this repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import re\n",
    "import numpy.matlib\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeformConv2D(nn.Module):\n",
    "    def __init__(self, inc, outc, kernel_size=3, padding=1, bias=None):\n",
    "        super(DeformConv2D, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        self.zero_padding = nn.ZeroPad2d(padding)\n",
    "        self.conv_kernel = nn.Conv2d(inc, outc, kernel_size=kernel_size, stride=kernel_size, bias=bias)\n",
    "\n",
    "    def forward(self, x, offset):\n",
    "        dtype = offset.data.type()\n",
    "        ks = self.kernel_size\n",
    "        N = offset.size(1) // 2\n",
    "\n",
    "        # Change offset's order from [x1, x2, ..., y1, y2, ...] to [x1, y1, x2, y2, ...]\n",
    "        # Codes below are written to make sure same results of MXNet implementation.\n",
    "        # You can remove them, and it won't influence the module's performance.\n",
    "\n",
    "        if self.padding:\n",
    "            x = self.zero_padding(x)\n",
    "\n",
    "        # (b, 2N, h, w)\n",
    "        p = self._get_p(offset, dtype)\n",
    "\n",
    "        # (b, h, w, 2N)\n",
    "        p = p.contiguous().permute(0, 2, 3, 1)\n",
    "        q_lt = Variable(p.data, requires_grad=False).floor()\n",
    "        q_rb = q_lt + 1\n",
    "\n",
    "        q_lt = torch.cat([torch.clamp(q_lt[..., :N], 0, x.size(2)-1), torch.clamp(q_lt[..., N:], 0, x.size(3)-1)], dim=-1).long()\n",
    "        q_rb = torch.cat([torch.clamp(q_rb[..., :N], 0, x.size(2)-1), torch.clamp(q_rb[..., N:], 0, x.size(3)-1)], dim=-1).long()\n",
    "        q_lb = torch.cat([q_lt[..., :N], q_rb[..., N:]], -1)\n",
    "        q_rt = torch.cat([q_rb[..., :N], q_lt[..., N:]], -1)\n",
    "\n",
    "        # (b, h, w, N)\n",
    "        mask = torch.cat([p[..., :N].lt(self.padding)+p[..., :N].gt(x.size(2)-1-self.padding),\n",
    "                          p[..., N:].lt(self.padding)+p[..., N:].gt(x.size(3)-1-self.padding)], dim=-1).type_as(p)\n",
    "        mask = mask.detach()\n",
    "        floor_p = p - (p - torch.floor(p))\n",
    "        p = p*(1-mask) + floor_p*mask\n",
    "        p = torch.cat([torch.clamp(p[..., :N], 0, x.size(2)-1), torch.clamp(p[..., N:], 0, x.size(3)-1)], dim=-1)\n",
    "\n",
    "        # bilinear kernel (b, h, w, N)\n",
    "        g_lt = (1 + (q_lt[..., :N].type_as(p) - p[..., :N])) * (1 + (q_lt[..., N:].type_as(p) - p[..., N:]))\n",
    "        g_rb = (1 - (q_rb[..., :N].type_as(p) - p[..., :N])) * (1 - (q_rb[..., N:].type_as(p) - p[..., N:]))\n",
    "        g_lb = (1 + (q_lb[..., :N].type_as(p) - p[..., :N])) * (1 - (q_lb[..., N:].type_as(p) - p[..., N:]))\n",
    "        g_rt = (1 - (q_rt[..., :N].type_as(p) - p[..., :N])) * (1 + (q_rt[..., N:].type_as(p) - p[..., N:]))\n",
    "\n",
    "        # (b, c, h, w, N)\n",
    "        x_q_lt = self._get_x_q(x, q_lt, N)\n",
    "        x_q_rb = self._get_x_q(x, q_rb, N)\n",
    "        x_q_lb = self._get_x_q(x, q_lb, N)\n",
    "        x_q_rt = self._get_x_q(x, q_rt, N)\n",
    "\n",
    "        # (b, c, h, w, N)\n",
    "        x_offset = g_lt.unsqueeze(dim=1) * x_q_lt + \\\n",
    "                   g_rb.unsqueeze(dim=1) * x_q_rb + \\\n",
    "                   g_lb.unsqueeze(dim=1) * x_q_lb + \\\n",
    "                   g_rt.unsqueeze(dim=1) * x_q_rt\n",
    "\n",
    "        x_offset = self._reshape_x_offset(x_offset, ks)\n",
    "        out = self.conv_kernel(x_offset)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def _get_p_n(self, N, dtype):\n",
    "        p_n_x, p_n_y = np.meshgrid(range(-(self.kernel_size-1)//2, (self.kernel_size-1)//2+1),\n",
    "                          range(-(self.kernel_size-1)//2, (self.kernel_size-1)//2+1), indexing='ij')\n",
    "        # (2N, 1)\n",
    "        p_n = np.concatenate((p_n_x.flatten(), p_n_y.flatten()))\n",
    "        p_n = np.reshape(p_n, (1, 2*N, 1, 1))\n",
    "        p_n = Variable(torch.from_numpy(p_n).type(dtype), requires_grad=False)\n",
    "\n",
    "        return p_n\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_p_0(h, w, N, dtype):\n",
    "        p_0_x, p_0_y = np.meshgrid(range(1, h+1), range(1, w+1), indexing='ij')\n",
    "        p_0_x = p_0_x.flatten().reshape(1, 1, h, w).repeat(N, axis=1)\n",
    "        p_0_y = p_0_y.flatten().reshape(1, 1, h, w).repeat(N, axis=1)\n",
    "        p_0 = np.concatenate((p_0_x, p_0_y), axis=1)\n",
    "        p_0 = Variable(torch.from_numpy(p_0).type(dtype), requires_grad=False)\n",
    "\n",
    "        return p_0\n",
    "\n",
    "    def _get_p(self, offset, dtype):\n",
    "        N, h, w = offset.size(1)//2, offset.size(2), offset.size(3)\n",
    "\n",
    "        # (1, 2N, 1, 1)\n",
    "        p_n = self._get_p_n(N, dtype)\n",
    "        # (1, 2N, h, w)\n",
    "        p_0 = self._get_p_0(h, w, N, dtype)\n",
    "        p = p_0 + p_n + offset\n",
    "        return p\n",
    "\n",
    "    def _get_x_q(self, x, q, N):\n",
    "        b, h, w, _ = q.size()\n",
    "        padded_w = x.size(3)\n",
    "        c = x.size(1)\n",
    "        # (b, c, h*w)\n",
    "        x = x.contiguous().view(b, c, -1)\n",
    "\n",
    "        # (b, h, w, N)\n",
    "        index = q[..., :N]*padded_w + q[..., N:]  # offset_x*w + offset_y\n",
    "        # (b, c, h*w*N)\n",
    "        index = index.contiguous().unsqueeze(dim=1).expand(-1, c, -1, -1, -1).contiguous().view(b, c, -1)\n",
    "\n",
    "        x_offset = x.gather(dim=-1, index=index).contiguous().view(b, c, h, w, N)\n",
    "\n",
    "        return x_offset\n",
    "\n",
    "    @staticmethod\n",
    "    def _reshape_x_offset(x_offset, ks):\n",
    "        b, c, h, w, N = x_offset.size()\n",
    "        x_offset = torch.cat([x_offset[..., s:s+ks].contiguous().view(b, c, h, w*ks) for s in range(0, N, ks)], dim=-1)\n",
    "        x_offset = x_offset.contiguous().view(b, c, h*ks, w*ks)\n",
    "\n",
    "        return x_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_conv_feature_maps = 60\n",
    "class SiameseBranch64(nn.Module):\n",
    "    def __init__(self,img_ch=3):\n",
    "        super(SiameseBranch64,self).__init__()\n",
    "        \n",
    "        self.Tanh = nn.Tanh() \n",
    "        self.Conv1 = nn.Conv2d(img_ch, num_conv_feature_maps, kernel_size = 3,stride=1,padding = 1,dilation = 1, bias=True)      \n",
    "        self.Conv2 = nn.Conv2d(num_conv_feature_maps, num_conv_feature_maps, kernel_size=3,stride=1,padding = 1,dilation = 1, bias=True)\n",
    "        self.Conv3 = nn.Conv2d(2*num_conv_feature_maps, num_conv_feature_maps, kernel_size=3,stride=1,padding = 1,dilation = 1, bias=True)\n",
    "        self.Conv4 = nn.Conv2d(3*num_conv_feature_maps, num_conv_feature_maps, kernel_size=3,stride=1,padding = 1,dilation = 1,bias=True)  \n",
    "        \n",
    "        \n",
    "    def forward(self,x_in):\n",
    "\n",
    "        x1 = self.Conv1(x_in) \n",
    "        x1 = self.Tanh(x1)\n",
    "                \n",
    "        x2 = self.Conv2(x1) \n",
    "        x2 = self.Tanh(x2)\n",
    "        \n",
    "        d2 = torch.cat((x1,x2),dim=1)\n",
    "        \n",
    "        x3 = self.Conv3(d2) \n",
    "        x3 = self.Tanh(x3)\n",
    "        \n",
    "        d3 = torch.cat((x1,x2,x3),dim=1)\n",
    "        x4 = self.Conv4(d3)\n",
    "        \n",
    "        return x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_sim_tanh = 40\n",
    "class SimMeasTanh(nn.Module):\n",
    "    def __init__(self,img_ch=2*num_conv_feature_maps):\n",
    "        super(SimMeasTanh,self).__init__()\n",
    "        \n",
    "        self.tanh = nn.Tanh() \n",
    "        \n",
    "        self.Conv1 = nn.Conv2d(img_ch, conv_sim_tanh, kernel_size = 3,stride=1,padding = 1,dilation = 1, bias=True)\n",
    "        self.Conv2 = nn.Conv2d(conv_sim_tanh, conv_sim_tanh, kernel_size=3,stride=1,padding = 1,dilation = 1, bias=True)\n",
    "        self.Conv3 = nn.Conv2d(2*conv_sim_tanh, conv_sim_tanh, kernel_size=3,stride=1,padding = 1,dilation = 1, bias=True)\n",
    "        self.Conv4 = nn.Conv2d(3*conv_sim_tanh, conv_sim_tanh, kernel_size=3,stride=1,padding = 1,dilation = 1, bias=True)\n",
    "        self.Conv5 = nn.Conv2d(4*conv_sim_tanh, 1, kernel_size=3,stride=1,padding = 1,dilation = 1, bias=True)\n",
    "        \n",
    "        self.conv_offset = nn.Conv2d(1, 18, kernel_size=3, padding=1, bias=None)\n",
    "        self.deform_conv = DeformConv2D(1, 1, padding=1)\n",
    "        \n",
    "    def forward(self,x_in):\n",
    "        \n",
    "        x1 = self.Conv1(x_in) \n",
    "        x1 = self.tanh(x1)\n",
    "                \n",
    "        x2 = self.Conv2(x1) \n",
    "        x2 = self.tanh(x2)\n",
    "        \n",
    "        d1 = torch.cat((x1,x2),dim=1)\n",
    "\n",
    "        \n",
    "        x3 = self.Conv3(d1) \n",
    "        x3 = self.tanh(x3)\n",
    "        \n",
    "        d2 = torch.cat((x1,x2,x3),dim=1)\n",
    "        \n",
    "        x4 = self.Conv4(d2) \n",
    "        x4 = self.tanh(x4) \n",
    "        d3 = torch.cat((x1,x2,x3,x4),dim=1)\n",
    "        x5 = self.Conv5(d3)\n",
    "        #needs to be positive for BCE!!!\n",
    "        x5 = self.tanh(x5) \n",
    "        \n",
    "        #deform_conv block!\n",
    "        offsets = self.conv_offset(x5)\n",
    "        x6 = self.deform_conv(x5,offsets)\n",
    "        \n",
    "        return x6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_conv_st1 = 70\n",
    "chan = 10\n",
    "class UpdateInconsNW(nn.Module):\n",
    "    def __init__(self,img_ch=chan):\n",
    "        super(UpdateInconsNW,self).__init__()\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "        self.Conv1 = nn.Conv2d(img_ch, n_conv_st1, kernel_size = 3,stride=1,padding = 1,dilation = 1, bias=True)\n",
    "        self.Conv2 = nn.Conv2d(n_conv_st1, n_conv_st1, kernel_size=3,stride=1,padding = 1,dilation = 1, bias=True)        \n",
    "        self.Conv4 = nn.Conv2d(n_conv_st1 + 3, img_ch, kernel_size=3,stride=1,padding = 1,dilation = 1, bias=True)\n",
    "        \n",
    "        \n",
    "    def forward(self,x_in, im):\n",
    "        \n",
    "        x1 = self.Conv1(x_in)\n",
    "        x1 = self.act(x1)\n",
    "                        \n",
    "        x2 = self.Conv2(x1)\n",
    "        x2 = self.act(x2)\n",
    "        \n",
    "        x3im = torch.cat((x2,im),axis = 1)\n",
    "        \n",
    "        x4 = self.Conv4(x3im)\n",
    "        x5 = self.softmax(x4)\n",
    "        \n",
    "        return x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "branch = SiameseBranch64()\n",
    "branch = branch.cuda()    \n",
    "\n",
    "simB = SimMeasTanh()\n",
    "simB = simB.cuda()\n",
    "\n",
    "updInc = UpdateInconsNW()\n",
    "updInc = updInc.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createShiftPytZero(image):\n",
    "    \n",
    "    counter = np.ones((image.shape[0],image.shape[1])) * chan\n",
    "    counterT = Variable(Tensor(counter))\n",
    "    \n",
    "    shift_arr = np.zeros((chan,image.shape[0],image.shape[1]))\n",
    "    shift_arrT = Variable(Tensor(shift_arr))\n",
    "\n",
    "    i = 0\n",
    "    while(torch.sum(counterT) > 0):\n",
    "\n",
    "        if(i == image.shape[1]):\n",
    "            i = 0\n",
    "            \n",
    "        if(i % 2 == 0):                \n",
    "            ex_s = torch.roll(image,-i)\n",
    "            ex_s[:,chan-i:chan] = 0\n",
    "            \n",
    "        if(i % 2 == 1):\n",
    "            ex_s = torch.roll(image,i)\n",
    "            ex_s[:,0:i] = 0\n",
    "            \n",
    "        \n",
    "        idc = torch.nonzero(ex_s, as_tuple = True)\n",
    "\n",
    "        counterT[idc[0],idc[1]] += -1\n",
    "        \n",
    "        max_loop = torch.min(counterT).cpu().data.numpy().astype(np.int)\n",
    "\n",
    "        #it overwrites lines that already have values with 0's!!!\n",
    "        for d in range(max_loop,chan):\n",
    "            \n",
    "            idx_cur = torch.where(counterT == d)\n",
    "            slice_tensor = torch.zeros(ex_s.shape[0], ex_s.shape[1]).cuda()\n",
    "            slice_tensor[idx_cur[0].long(),idx_cur[1].long()] = ex_s[idx_cur[0].long(),idx_cur[1].long()]\n",
    "            \n",
    "            idc_slice = torch.nonzero(slice_tensor, as_tuple = True)\n",
    "            shift_arrT[d, idc_slice[0].long(),idc_slice[1].long()] = ex_s[idc_slice[0].long(),idc_slice[1].long()]\n",
    "            \n",
    "        counterT[counterT < 0] = 0\n",
    "        i = i + 1\n",
    "                    \n",
    "    return shift_arrT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestFillIncons(nr_iter, disp, im_left):    \n",
    "    \n",
    "    disp[np.isnan(disp)] = 0\n",
    "    disp[np.isinf(disp)] = 0\n",
    "        \n",
    "    \n",
    "    im = cv2.imread(im_left)    \n",
    "    im = (im - np.min(im)) / (np.max(im) - np.min(im))\n",
    "\n",
    "    h,w,c = im.shape\n",
    "    im = np.reshape(im, (c,h, w))\n",
    "    im = im[np.newaxis,...]        \n",
    "    imT = Variable(Tensor(im.astype(np.uint8)))\n",
    "\n",
    "    upd = np.zeros((disp.shape[0],disp.shape[1]))\n",
    "    upd[np.where(disp == 0)] = 1\n",
    "\n",
    "    keep = np.zeros((disp.shape[0],disp.shape[1]))\n",
    "    keep[np.where(upd == 0)] = 1\n",
    "\n",
    "    keep_t = disp * keep\n",
    "    \n",
    "    updT = Variable(Tensor(upd.astype(np.float32)))\n",
    "    keepT_t = Variable(Tensor(keep_t.astype(np.float32)))\n",
    "    \n",
    "    dispT = Variable(Tensor(disp.astype(np.uint8)))\n",
    "    \n",
    "    for d in range(0,nr_iter):\n",
    "\n",
    "        dispShift = createShiftPytZero(dispT)\n",
    "        dispShift = dispShift.unsqueeze(0)\n",
    "        \n",
    "        OutT = updInc(dispShift,imT) \n",
    "        OutT = torch.squeeze(OutT)\n",
    "\n",
    "        bs,c,x,y = dispShift.shape\n",
    "\n",
    "        idc_for_updt = torch.argmax(OutT, axis=0).unsqueeze(0)  \n",
    "        pred = torch.gather(np.squeeze(dispShift), 0, idc_for_updt).squeeze()\n",
    "        \n",
    "        updT_t = pred * updT\n",
    "        final_outp = keepT_t + updT_t\n",
    "        dispT = final_outp",
    "        \n",
    "        \n",
    "    disp_arr = final_outp.cpu().data.numpy().astype(np.float32)\n",
    "    return disp_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readPFM(file):\n",
    "    file = open(file, 'rb')\n",
    "\n",
    "    color = None\n",
    "    width = None\n",
    "    height = None\n",
    "    scale = None\n",
    "    endian = None\n",
    "\n",
    "    header = file.readline().decode('utf-8').rstrip()\n",
    "    if header == 'PF':\n",
    "        color = True\n",
    "    elif header == 'Pf':\n",
    "        color = False\n",
    "    else:\n",
    "        raise Exception('Not a PFM file.')\n",
    "\n",
    "    dim_match = re.match(r'^(\\d+)\\s(\\d+)\\s$', file.readline().decode('utf-8'))\n",
    "    if dim_match:\n",
    "        width, height = map(int, dim_match.groups())\n",
    "    else:\n",
    "        raise Exception('Malformed PFM header.')\n",
    "\n",
    "    scale = float(file.readline().decode('utf-8').rstrip())\n",
    "    if scale < 0:  # little-endian\n",
    "        endian = '<'\n",
    "        scale = -scale\n",
    "    else:\n",
    "        endian = '>'  # big-endian\n",
    "\n",
    "    data = np.fromfile(file, endian + 'f')\n",
    "    shape = (height, width, 3) if color else (height, width)\n",
    "\n",
    "    data = np.reshape(data, shape)\n",
    "    data = np.flipud(data)\n",
    "    return data, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor = torch.cuda.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def _compute_binary_kernel(window_size: Tuple[int, int]) -> torch.Tensor:\n",
    "    r\"\"\"Creates a binary kernel to extract the patches. If the window size\n",
    "    is HxW will create a (H*W)xHxW kernel.\n",
    "    \"\"\"\n",
    "    window_range: int = window_size[0] * window_size[1]\n",
    "    kernel: torch.Tensor = torch.zeros(window_range, window_range)\n",
    "    for i in range(window_range):\n",
    "        kernel[i, i] += 1.0\n",
    "    return kernel.view(window_range, 1, window_size[0], window_size[1])\n",
    "\n",
    "\n",
    "def _compute_zero_padding(kernel_size: Tuple[int, int]) -> Tuple[int, int]:\n",
    "    r\"\"\"Utility function that computes zero padding tuple.\"\"\"\n",
    "    computed: Tuple[int, ...] = tuple([(k - 1) // 2 for k in kernel_size])\n",
    "    return computed[0], computed[1]\n",
    "\n",
    "\n",
    "class MedianBlur(nn.Module):\n",
    "    r\"\"\"Blurs an image using the median filter.\n",
    "\n",
    "    Args:\n",
    "        kernel_size (Tuple[int, int]): the blurring kernel size.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: the blurred input tensor.\n",
    "\n",
    "    Shape:\n",
    "        - Input: :math:`(B, C, H, W)`\n",
    "        - Output: :math:`(B, C, H, W)`\n",
    "\n",
    "    Example:\n",
    "        >>> input = torch.rand(2, 4, 5, 7)\n",
    "        >>> blur = kornia.filters.MedianBlur((3, 3))\n",
    "        >>> output = blur(input)  # 2x4x5x7\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size: Tuple[int, int]) -> None:\n",
    "        super(MedianBlur, self).__init__()\n",
    "        self.kernel: torch.Tensor = _compute_binary_kernel(kernel_size)\n",
    "        self.padding: Tuple[int, int] = _compute_zero_padding(kernel_size)\n",
    "\n",
    "    def forward(self, input: torch.Tensor):  # type: ignore\n",
    "        if not torch.is_tensor(input):\n",
    "            raise TypeError(\"Input type is not a torch.Tensor. Got {}\"\n",
    "                            .format(type(input)))\n",
    "        if not len(input.shape) == 4:\n",
    "            raise ValueError(\"Invalid input shape, we expect BxCxHxW. Got: {}\"\n",
    "                             .format(input.shape))\n",
    "        # prepare kernel\n",
    "        b, c, h, w = input.shape\n",
    "        tmp_kernel: torch.Tensor = self.kernel.to(input.device).to(input.dtype)\n",
    "        kernel: torch.Tensor = tmp_kernel.repeat(c, 1, 1, 1)\n",
    "\n",
    "        # map the local window to single vector\n",
    "        features: torch.Tensor = F.conv2d(\n",
    "            input, kernel, padding=self.padding, stride=1, groups=c)\n",
    "        features = features.view(b, c, -1, h, w)  # BxCx(K_h * K_w)xHxW\n",
    "\n",
    "        # compute the median along the feature axis\n",
    "        median: torch.Tensor = torch.median(features, dim=2)[0]\n",
    "        return median\n",
    "\n",
    "# functiona api\n",
    "def median_blur(input: torch.Tensor,\n",
    "                kernel_size: Tuple[int, int]) -> torch.Tensor:\n",
    "    r\"\"\"Blurs an image using the median filter.\n",
    "\n",
    "    See :class:`~kornia.filters.MedianBlur` for details.\n",
    "    \"\"\"\n",
    "    return MedianBlur(kernel_size)(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterCostVolMedianPyt(cost_vol):\n",
    "    \n",
    "    d,h,w = cost_vol.shape\n",
    "    cost_vol = cost_vol.unsqueeze(0)\n",
    "    \n",
    "    for disp in range(d):\n",
    "\n",
    "        cost_vol[:,disp,:,:] = median_blur(cost_vol[:,disp,:,:].unsqueeze(0), (5,5))\n",
    "        \n",
    "    return torch.squeeze(cost_vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from guided_filter_pytorch.guided_filter import GuidedFilter\n",
    "def filterCostVolBilatpyt(cost_vol,left):\n",
    "    \n",
    "    left = np.mean(left,axis=2)\n",
    "    leftT = Variable(Tensor(left))\n",
    "    leftT = leftT.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    d,h,w = cost_vol.shape  \n",
    "    \n",
    "    f = GuidedFilter(8,10).cuda()  #10 #0.001\n",
    "    \n",
    "    for disp in range(d):\n",
    "        cur_slice =  cost_vol[disp,:,:]\n",
    "        cur_slice = cur_slice.unsqueeze(0).unsqueeze(0)\n",
    "        \n",
    "        inputs = [leftT, cur_slice]\n",
    "\n",
    "        test = f(*inputs)\n",
    "        cost_vol[disp,:,:] = np.squeeze(test)\n",
    "        \n",
    "    return cost_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#even further improve this by using pytorch!\n",
    "def LR_Check(first_output, second_output):    \n",
    "    \n",
    "    h,w = first_output.shape\n",
    "        \n",
    "    line = np.array(range(0, w))\n",
    "    idx_arr = np.matlib.repmat(line,h,1)    \n",
    "    \n",
    "    dif = idx_arr - first_output\n",
    "    \n",
    "    first_output[np.where(dif <= 0)] = 0\n",
    "    \n",
    "    first_output = first_output.astype(np.int)\n",
    "    second_output = second_output.astype(np.int)\n",
    "    dif = dif.astype(np.int)\n",
    "    \n",
    "    second_arr_reordered = np.array(list(map(lambda x, y: y[x], dif, second_output)))\n",
    "    \n",
    "    dif_LR = np.abs(second_arr_reordered - first_output)\n",
    "    first_output[np.where(dif_LR >= 1.1)] = 0\n",
    "    \n",
    "    first_output = first_output.astype(np.float32)\n",
    "    first_output[np.where(first_output == 0.0)] = np.nan\n",
    "            \n",
    "    return first_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCostVol(left_im,right_im,max_disp):\n",
    "        \n",
    "    a_h, a_w,c = left_im.shape\n",
    "\n",
    "    left_im = np.transpose(left_im, (2,0,1)).astype(np.uint8)\n",
    "    right_im = np.transpose(right_im, (2,0,1)).astype(np.uint8)\n",
    "    \n",
    "    left_im = np.reshape(left_im, [1,c,a_h,a_w])\n",
    "    right_im = np.reshape(right_im, [1,c,a_h,a_w])\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        left_imT = Variable(Tensor(left_im.astype(np.uint8)))\n",
    "        right_imT = Variable(Tensor(right_im.astype(np.uint8)))\n",
    "\n",
    "        left_feat = branch(left_imT)\n",
    "        right_feat = branch(right_imT)\n",
    "        \n",
    "        _,f,h,w = left_feat.shape\n",
    "        \n",
    "        cost_vol = np.zeros((max_disp+1,a_h,a_w))\n",
    "        cost_volT = Variable(Tensor(cost_vol))\n",
    "        \n",
    "        for disp in range(0,max_disp+1):\n",
    "\n",
    "            if(disp == 0):\n",
    "                \n",
    "                sim_score = simB(torch.cat((left_feat, right_feat),dim=1))\n",
    "                cost_volT[disp,:,:] = torch.squeeze(sim_score)                \n",
    "            else:\n",
    "                right_shifted = torch.cuda.FloatTensor(1,f,h,w).fill_(0)                      \n",
    "                right_shift = torch.cuda.FloatTensor(1,f,h,disp).fill_(0)  \n",
    "                right_appended = torch.cat([right_shift,right_feat],3)\n",
    "\n",
    "                _,f,h_ap,w_ap = right_appended.shape\n",
    "                right_shifted[:,:,:,:] = right_appended[:,:,:,:(w_ap-disp)]\n",
    "                sim_score = simB(torch.cat((left_feat, right_shifted),dim=1))                \n",
    "                cost_volT[disp,:,:] = torch.squeeze(sim_score)   \n",
    "                \n",
    "    return cost_volT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCostVolRL(left_im,right_im,max_disp):\n",
    "\n",
    "    a_h, a_w,c = left_im.shape\n",
    "\n",
    "    left_im = np.transpose(left_im, (2,0,1)).astype(np.uint8)\n",
    "    right_im = np.transpose(right_im, (2,0,1)).astype(np.uint8)\n",
    "    \n",
    "    left_im = np.reshape(left_im, [1,c,a_h,a_w])\n",
    "    right_im = np.reshape(right_im, [1,c,a_h,a_w])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        left_imT = Variable(Tensor(left_im))\n",
    "        right_imT = Variable(Tensor(right_im))\n",
    "\n",
    "        left_feat = branch(left_imT)\n",
    "        right_feat = branch(right_imT)\n",
    "\n",
    "\n",
    "        _,f,h,w = left_feat.shape\n",
    "        cost_vol = np.zeros((max_disp+1,a_h,a_w))\n",
    "        \n",
    "        cost_volT = Variable(Tensor(cost_vol))\n",
    "\n",
    "        for disp in range(0,max_disp+1):\n",
    "\n",
    "            if(disp == 0):\n",
    "                sim_score = simB(torch.cat((left_feat, right_feat),dim=1))\n",
    "                cost_volT[disp,:,:] = torch.squeeze(sim_score) \n",
    "            else:    \n",
    "                left_shifted = torch.cuda.FloatTensor(1,f,h,w).fill_(0)\n",
    "                left_shift = torch.cuda.FloatTensor(1,f,h,disp).fill_(0)\n",
    "                left_appended = torch.cat([left_feat,left_shift],3)\n",
    "\n",
    "                _,f,h_ap,w_ap = left_appended.shape\n",
    "                left_shifted[:,:,:,:] = left_appended[:,:,:,disp:w_ap]\n",
    "            \n",
    "                sim_score = simB(torch.cat((left_shifted, right_feat),dim=1))\n",
    "                cost_volT[disp,:,:] = torch.squeeze(sim_score)\n",
    "                \n",
    "    return cost_volT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestImage(fn_left, fn_right, max_disp, filtered, lr_check):\n",
    "    \n",
    "    left = cv2.imread(fn_left)\n",
    "    right = cv2.imread(fn_right)\n",
    "    disp_map = []\n",
    "    \n",
    "    if(filtered):\n",
    "        cost_vol = createCostVol(left,right,max_disp)\n",
    "        \n",
    "        cost_vol_filteredn = filterCostVolBilatpyt(cost_vol,left)\n",
    "        cost_vol_filteredn = np.squeeze(cost_vol_filteredn.cpu().data.numpy())                \n",
    "        disp = np.argmax(cost_vol_filteredn, axis=0) \n",
    "        \n",
    "        del cost_vol\n",
    "        del cost_vol_filteredn\n",
    "        torch.cuda.empty_cache()              \n",
    "        \n",
    "        if(lr_check):\n",
    "            cost_vol_RL = createCostVolRL(left,right,max_disp)\n",
    "            \n",
    "            cost_vol_RL_fn = filterCostVolBilatpyt(cost_vol_RL,right)\n",
    "            cost_vol_RL_fn = np.squeeze(cost_vol_RL_fn.cpu().data.numpy())        \n",
    "            \n",
    "            disp_map_RL = np.argmax(cost_vol_RL_fn, axis=0)  \n",
    "            disp_map = LR_Check(disp.astype(np.float32), disp_map_RL.astype(np.float32))\n",
    "            \n",
    "            del cost_vol_RL\n",
    "            del cost_vol_RL_fn\n",
    "            torch.cuda.empty_cache()              \n",
    "        \n",
    "    else:\n",
    "        cost_vol = createCostVol(left,right,max_disp)\n",
    "        cost_vol = np.squeeze(cost_vol.cpu().data.numpy())\n",
    "        disp = np.argmax(cost_vol, axis=0)        \n",
    "        \n",
    "        if(lr_check):\n",
    "            \n",
    "            cost_vol_RL = createCostVolRL(left,right,max_disp)\n",
    "            cost_vol_RL = np.squeeze(cost_vol_RL.cpu().data.numpy())\n",
    "            disp_map_RL = np.argmax(cost_vol_RL, axis=0)       \n",
    "            disp_map = LR_Check(disp.astype(np.float32), disp_map_RL.astype(np.float32))\n",
    "    \n",
    "    if(lr_check):\n",
    "        return disp_map, disp, disp_map_RL\n",
    "    else:\n",
    "        return disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writePFM(file, image, scale=1):\n",
    "    file = open(file, 'wb')\n",
    "\n",
    "    color = None\n",
    "\n",
    "    if image.dtype.name != 'float32':\n",
    "        raise Exception('Image dtype must be float32.')\n",
    "\n",
    "    image = np.flipud(image)\n",
    "\n",
    "    if len(image.shape) == 3 and image.shape[2] == 3:  # color image\n",
    "        color = True\n",
    "    elif len(image.shape) == 2 or len(image.shape) == 3 and image.shape[2] == 1:  # greyscale\n",
    "        color = False\n",
    "    else:\n",
    "        raise Exception('Image must have H x W x 3, H x W x 1 or H x W dimensions.')\n",
    "\n",
    "    file.write('PF\\n'.encode() if color else 'Pf\\n'.encode())\n",
    "    file.write('%d %d\\n'.encode() % (image.shape[1], image.shape[0]))\n",
    "\n",
    "    endian = image.dtype.byteorder\n",
    "\n",
    "    if endian == '<' or endian == '=' and sys.byteorder == 'little':\n",
    "        scale = -scale\n",
    "\n",
    "    file.write('%f\\n'.encode() % scale)\n",
    "\n",
    "    image.tofile(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writePFMcyt(file, image, scale=1):\n",
    "    file = open(file, 'wb')\n",
    "\n",
    "    color = None\n",
    "\n",
    "    image = np.flipud(image)\n",
    "\n",
    "    if len(image.shape) == 3 and image.shape[2] == 3:  # color image\n",
    "        color = True\n",
    "    elif len(image.shape) == 2 or len(image.shape) == 3 and image.shape[2] == 1:  # greyscale\n",
    "        color = False\n",
    "    else:\n",
    "        raise Exception('Image must have H x W x 3, H x W x 1 or H x W dimensions.')\n",
    "\n",
    "    file.write('PF\\n'.encode() if color else 'Pf\\n'.encode())\n",
    "    file.write('%d %d\\n'.encode() % (image.shape[1], image.shape[0]))\n",
    "\n",
    "    endian = image.dtype.byteorder\n",
    "\n",
    "    scale = -scale\n",
    "\n",
    "    file.write('%f\\n'.encode() % scale)\n",
    "\n",
    "    image.tofile(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_branch = '/media/HDD/FCDSN-DC_GITHUB/FCDSN-DC/save/branch/mb'\n",
    "w_simb = '/media/HDD/FCDSN-DC_GITHUB/FCDSN-DC/save/simb/mb_simB'\n",
    "w_incons = '/media/HDD/FCDSN-DC_GITHUB/FCDSN-DC/save/fill/Incons'\n",
    "\n",
    "left_im = '/media/HDD/FCDSN-DC_GITHUB/FCDSN-DC/example/im0.png'\n",
    "right_im = '/media/HDD/FCDSN-DC_GITHUB/FCDSN-DC/example/im1.png'\n",
    "max_disp = 140\n",
    "\n",
    "save = True\n",
    "out_folder = '/media/HDD/FCDSN-DC_GITHUB/FCDSN-DC/'\n",
    "out_name = 'motor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "branch.load_state_dict(torch.load(w_branch))\n",
    "simB.load_state_dict(torch.load(w_simb))\n",
    "filtered = True\n",
    "lr_check = True\n",
    "disp_s, disp, disp_rl = TestImage(left_im, right_im, max_disp, filtered, lr_check)\n",
    "writePFM(out_folder + out_name + '.pfm', disp.astype(np.float32), scale=1)     \n",
    "writePFM(out_folder + out_name + '_s.pfm', disp_s.astype(np.float32), scale=1)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "updInc.load_state_dict(torch.load(w_incons))\n",
    "filled_disp = TestFillIncons(5, disp_s, left_im)\n",
    "writePFM(out_folder + out_name + '_filled.pfm', filled_disp.astype(np.float32), scale=1)     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
